        - 
        - module MulticlassPerceptron
        - export predict, MPerceptron, fit!
        - 
        - type MPerceptron{T}
   101480     W::AbstractMatrix
        -     b::AbstractVector{T}
        -     n_classes::Int
        -     n_features::Int
        -     accuracy::AbstractVector{T}
        - end
        - 
        - function Base.show{T}(io::IO, p::MPerceptron{T})
        -     n_classes  = p.n_classes
        -     n_features = p.n_features
        -     print(io, "Perceptron{$T}(n_classes=$n_classes, n_features=$n_features)")
        - end
        - 
        0 MPerceptron(T::Type, n_classes::Int, n_features::Int) = MPerceptron(rand(T, n_features, n_classes),
        -                                                                     zeros(T, n_classes),
        -                                                                     n_classes,
        -                                                                     n_features,
        -                                                                     zeros(T,0))
        - """
        - Compute the accuracy betwwen `y` and `y_hat`.
        - """
        - function accuracy(y, y_hat)
        0     acc = 0.
        0     @inbounds for k = 1:length(y)
        0                 @fastmath  acc += y[k] == y_hat[k]
        -               end
        0     return acc/length(y_hat)
        - end
        - 
        - """
        - Function to predict the class for a given input in a `MPerceptron`.
        - The placeholder is used to avoid allocating memory for each matrix-vector multiplication.
        - 
        - - Returns the predicted class.
        - """
        - function predict(h::MPerceptron, x, placeholder)
        0     placeholder .= At_mul_B!(placeholder, h.W, x) .+ h.b
        0     return indmax(placeholder)
        - end
        - 
        - """
        - Function to predict the class for a given input in a `MPerceptron`.
        - 
        - - Returns the predicted class.
        - """
        - function predict(h::MPerceptron, x)
        -     return indmax(h.W' * x .+ h.b)
        - end
        - 
        - """
        - >    fit!(h::Perceptron,
        - >         X::Array,
        - >         y::Array;
        - >         n_epochs=50,
        - >         learning_rate=0.1,
        - >         print_flag=false,
        - >         compute_accuracy=true,
        - >         seed=srand(1234),
        - >         pocket=false,
        - >         shuffle_data=false)
        - 
        - ##### Arguments
        - 
        - - **`h`**, (MPerceptron{T} type), initialized perceptron.
        - - **`X`**, (Array{T,2} type), data contained in the columns of X.
        - - **`y`**, (Vector{T} type), class labels (as integers from 1 to n_classes).
        - 
        - ##### Keyword arguments
        - 
        - - **`n_epochs`**, (Integer type), number of passes (epochs) through the data.
        - - **`learning_rate`**, (Float type), learning rate (The standard perceptron is with learning_rate=1.)
        - - **`compute_accuracy`**, (Bool type), if `true` the accuracy is computed at the end of every epoch.
        - - **`print_flag`**, (Bool type), if `true` the accuracy is printed at the end of every epoch.
        - - **`seed`**, (MersenneTwister type), seed for the permutation of the datapoints in case there the data is shuffled.
        - - **`pocket`** , (Bool type), if `true` the best weights are saved (in the pocket) during learning.
        - - **`shuffle_data`**, (Bool type),  if `true` the data is shuffled at every epoch (in reality we only shuffle indicies for performance).
        - 
        - """
        - function fit!(h::MPerceptron, X::AbstractArray, y::Vector;
        -               n_epochs=50, learning_rate=1., print_flag=false, 
        -               compute_accuracy=false, seed=srand(1234), pocket=false, 
        -               shuffle_data=false, average_weights = false)
        - 
        -     #n_features, n_samples = size(X)
        -     #@assert eltype(X) == eltype(h.W)
  5049895     n_features = size(X,1)
        0     n_samples = size(X,2)
        -     
        0     @assert length(y) == n_samples
        - 
        - 
        -     T = eltype(X)
        0     learning_rate = T(learning_rate)
        - 
        0     y_signal_placeholder = zeros(T, h.n_classes)
   480080     y_preds = zeros(Int64, n_samples)
        0     data_indices = Array(1:n_samples)
        0     max_acc = zero(T)
        - 
        0     if pocket
        0         W_hat = zeros(T, h.n_features, h.n_classes)
        0         b_hat = zeros(T, h.n_classes)
        -     end
        0     if average_weights
        0         W_his = zeros(T, h.n_features, h.n_classes)
        0         b_his = zeros(T, h.n_classes)
        -     end
        - 
        0     for epoch in 1:n_epochs
        - 
        0         n_mistakes = 0
        0         if shuffle_data
        0             shuffle!(seed, data_indices)
        -         end
        - 
        0         @inbounds for m in data_indices
        -             #x = view(X, :, m)
 28800000             x = view(X, :, m)
        - 
        0             y_hat = predict(h, x, y_signal_placeholder)
        -             #y_hat = predict(h, x)
        -             
        0             if y[m] != y_hat
        0                 n_mistakes += 1
        -                 ####  wij ← wij − η (yj −tj) · xi
        - 
        0                 h.W[:, y[m]]  .= h.W[:, y[m]]  .+ learning_rate .* x
        0                 h.b[y[m]]     .= h.b[y[m]]     .+ learning_rate
        0                 h.W[:, y_hat] .= h.W[:, y_hat] .- learning_rate .* x
        0                 h.b[y_hat]    .= h.b[y_hat]    .- learning_rate
        - 
        -                 #h.W[:, y[m]]  .= h.W[:, y[m]]  .+ learning_rate .* x
        -                 #h.b[y[m]]     .= h.b[y[m]]     .+ learning_rate
        -                 #h.W[:, y_hat] .= h.W[:, y_hat] .- learning_rate .* x
        -                 #h.b[y_hat]    .= h.b[y_hat]    .- learning_rate
        -             end
        -         end
        - 
        0         if compute_accuracy
        0              @inbounds for m in  data_indices
        0                  y_preds[m] = predict(h, view(X, :, m), y_signal_placeholder)
        -             end
        0             acc = accuracy(y, y_preds)
        0             push!(h.accuracy, acc)
        -         else
        0             acc = (n_samples - n_mistakes)/n_samples
        0             push!(h.accuracy, acc)
        -         end
        - 
        0         if pocket
        0             if acc > max_acc
        0                 max_acc = acc
        0                 copy!(W_hat, h.W)
        0                 copy!(b_hat, h.b)
        -             end
        -         end
        0         if average_weights
        0             W_his .=  W_his .+ h.W
        0             b_his .=  b_his .+ h.b
        -         end
        -         
        0         if print_flag 
        0             print("Epoch: $(epoch) \t Accuracy: $(round(acc,3))\r")
        0             flush(STDOUT)
        -         end
        -     end
        - 
        0     if compute_accuracy && pocket
        0         h.W .= W_hat
        0         h.b .= b_hat
        -     end
        0     if average_weights
        0         println("history weights\n",W_his[1:5])
        0         println("weights\n",h.W[1:5])
        0         println("history weights scaled\n",W_his[1:5]/n_epochs)
        0         h.W .= W_his/n_epochs
        0         h.b .= b_his/n_epochs
        -     end
        - 
        0     return
        - end
        - 
        - end
        - 

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking Perceptron\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets\n",
    "using BenchmarkTools\n",
    "#using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.458961641658127e10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peakflops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 0.6.0\n",
      "Commit 903644385b (2017-06-19 13:05 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin13.4.0)\n",
      "  CPU: Intel(R) Xeon(R) CPU E5-1620 v2 @ 3.70GHz\n",
      "  WORD_SIZE: 64\n",
      "  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Sandybridge)\n",
      "  LAPACK: libopenblas64_\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-3.9.1 (ORCJIT, ivybridge)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_path = join(push!(split(pwd(),\"/\")[1:end-1],\"source/\" ),\"/\")\n",
    "\n",
    "if !contains(==,LOAD_PATH, source_path) \n",
    "    push!(LOAD_PATH, source_path)\n",
    "end\n",
    "\n",
    "using MulticlassPerceptron\n",
    "percep = MulticlassPerceptron.MPerceptron(Float32, 10,784)\n",
    "n_features = 784\n",
    "\n",
    "X_train, y_train = MLDatasets.MNIST.traindata();\n",
    "X_test, y_test = MLDatasets.MNIST.testdata();\n",
    "X_train = reshape(X_train, 784, 60000);\n",
    "X_test = reshape(X_test, 784, 10000);\n",
    "\n",
    "y_train = y_train + 1\n",
    "y_test = y_test + 1;\n",
    "\n",
    "T = Float32\n",
    "X_train = Array{T}((X_train - minimum(X_train))/(maximum(X_train) - minimum(X_train)))\n",
    "y_train = Array{Int64}(y_train)\n",
    "X_test = Array{T}(X_test - minimum(X_test))/(maximum(X_test) - minimum(X_test)) \n",
    "y_test = Array{Int64}(y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> fit!(h::Perceptron,         X::Array,         y::Array;         n_epochs=50,         learning_rate=0.1,         print_flag=false,         compute_accuracy=true,         seed=srand(1234),         pocket=false,         shuffle_data=false)\n",
       "\n",
       "\n",
       "##### Arguments\n",
       "\n",
       "  * **`h`**, (MPerceptron{T} type), initialized perceptron.\n",
       "  * **`X`**, (Array{T,2} type), data contained in the columns of X.\n",
       "  * **`y`**, (Vector{T} type), class labels (as integers from 1 to n_classes).\n",
       "\n",
       "##### Keyword arguments\n",
       "\n",
       "  * **`n_epochs`**, (Integer type), number of passes (epochs) through the data.\n",
       "  * **`learning_rate`**, (Float type), learning rate (The standard perceptron is with learning_rate=1.)\n",
       "  * **`compute_accuracy`**, (Bool type), if `true` the accuracy is computed at the end of every epoch.\n",
       "  * **`print_flag`**, (Bool type), if `true` the accuracy is printed at the end of every epoch.\n",
       "  * **`seed`**, (MersenneTwister type), seed for the permutation of the datapoints in case there the data is shuffled.\n",
       "  * **`pocket`** , (Bool type), if `true` the best weights are saved (in the pocket) during learning.\n",
       "  * **`shuffle_data`**, (Bool type),  if `true` the data is shuffled at every epoch (in reality we only shuffle indicies for performance).\n"
      ],
      "text/plain": [
       "> fit!(h::Perceptron,         X::Array,         y::Array;         n_epochs=50,         learning_rate=0.1,         print_flag=false,         compute_accuracy=true,         seed=srand(1234),         pocket=false,         shuffle_data=false)\n",
       "\n",
       "\n",
       "##### Arguments\n",
       "\n",
       "  * **`h`**, (MPerceptron{T} type), initialized perceptron.\n",
       "  * **`X`**, (Array{T,2} type), data contained in the columns of X.\n",
       "  * **`y`**, (Vector{T} type), class labels (as integers from 1 to n_classes).\n",
       "\n",
       "##### Keyword arguments\n",
       "\n",
       "  * **`n_epochs`**, (Integer type), number of passes (epochs) through the data.\n",
       "  * **`learning_rate`**, (Float type), learning rate (The standard perceptron is with learning_rate=1.)\n",
       "  * **`compute_accuracy`**, (Bool type), if `true` the accuracy is computed at the end of every epoch.\n",
       "  * **`print_flag`**, (Bool type), if `true` the accuracy is printed at the end of every epoch.\n",
       "  * **`seed`**, (MersenneTwister type), seed for the permutation of the datapoints in case there the data is shuffled.\n",
       "  * **`pocket`** , (Bool type), if `true` the best weights are saved (in the pocket) during learning.\n",
       "  * **`shuffle_data`**, (Bool type),  if `true` the data is shuffled at every epoch (in reality we only shuffle indicies for performance).\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?MulticlassPerceptron.fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the percep in the MNIST\n",
    "\n",
    "  2.430426 seconds (2.37 M allocations: 512.297 MiB, 13.22% gc time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron{Float32}(n_classes=10, n_features=784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percep = MulticlassPerceptron.MPerceptron(Float32, 10, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.501581 seconds (8.84 M allocations: 696.995 MiB, 3.55% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time fit!(percep, X_train, y_train; n_epochs=10, print_flag=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.561922 seconds (663.24 k allocations: 56.801 MiB, 1.26% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time fit!(percep, X_train, y_train; n_epochs=1, print_flag=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670.266875 seconds (3.98 G allocations: 59.326 GiB, 0.49% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time fit2!(percep, X_train, y_train; n_epochs=10, print_flag=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percep.W[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "percep.W[1,2]  = percep.W[1,2]*23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_hat = [ predict(percep,view(X_test,:,m)) for m in 1:size(X_test,2) ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(y_test_hat .== y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged Perceptron vs standard perceptron\n",
    "\n",
    "- ERROR! -> They seem to return the exact same weights!\n",
    "- NOTICE: Given the same seed they should return the same accuracy per epoch values since the weights during learning are the same. Nevertheless once learning is finished the averaged perceptron should have different weights since they are changed by the average of the weights present during learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = size(X_train,2)\n",
    "@time Array(1:n_samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames(percep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percep = MulticlassPerceptron.MPerceptron(Float32, 10,784)\n",
    "fit!(percep, X_train, y_train;\n",
    "     n_epochs=5, print_flag=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percep.W[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_percep = MulticlassPerceptron.MPerceptron(Float32, 10,784)\n",
    "fit!(av_percep, X_train, y_train;\n",
    "     n_epochs=5, average_weights=true, print_flag=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_percep.W[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percep.accuracy[1:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_percep.accuracy[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_percep.W[1:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percep.W[1:4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data at every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percep = MulticlassPerceptron.MPerceptron(Float32, 10,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit!(percep, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percep.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the code\n",
    "\n",
    "\n",
    "\n",
    "#### About profiling julia code\n",
    "\n",
    "- https://thirld.com/blog/2015/05/30/julia-profiling-cheat-sheet/\n",
    "\n",
    "#### Examples of speeding up code\n",
    "\n",
    "There is a small number of \"tricks\" that can be applied to speed up execution time and save memory allocations. This is paramount for enjoying C like speed with julia code.\n",
    "\n",
    "- https://discourse.julialang.org/t/speed-up-this-code-game/3666\n",
    "\n",
    "## Allowing perceptron to use Sparse Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = MulticlassPerceptron.MPerceptron(Float32, 10,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsp = sparse(zeros(100,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_sp = sparse(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time MulticlassPerceptron.predict(h, X_tr_sp[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@time MulticlassPerceptron.predict(h, X_train[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is sparse multiplication slower ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = deepcopy(X_tr_sp[:,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time indmax(h.W' * x .+ h.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hW = sparse(rand(T, 784, 10));\n",
    "hb = sparse(zeros(T,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(hb), typeof(hW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eltype(hW), eltype(hb), eltype(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time indmax(hW' * x .+ hb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time MulticlassPerceptron.predict(h, X_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function testspeedsparse(hW,x,hb)\n",
    "    for i in 1:100 \n",
    "        indmax(hW' * x .+ hb)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is the sparse version slower??\n",
    "@time testspeedsparse(hW,x,hb)\n",
    "@time testspeedsparse(h.W,X_train[:,1],h.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The slowness does not come from the indmax function\n",
    "# the same happens in this version\n",
    "function testspeedsparse_(hW, x, hb)\n",
    "    for i in 1:100 \n",
    "        hW' * x .+ hb\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time testspeedsparse_(hW,x,hb)\n",
    "@time testspeedsparse_(h.W,X_train[:,1],h.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### It does not seem worth to use views when data is\n",
    "#    a sparse matrix operations\n",
    "@time X_tr_sp[:,1];\n",
    "@time view(X_tr_sp,:,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hW' * x .+ hb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time for i in 1:100000 X_train[:,1] end\n",
    "@time for i in 1:100000  view(X_train,:,1) end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## defining pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.0-rc2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

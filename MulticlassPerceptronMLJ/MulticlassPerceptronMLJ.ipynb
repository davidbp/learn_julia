{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using MetadataTools,  DocStringExtensions\n",
    "using Random: shuffle, MersenneTwister\n",
    "\n",
    "# export MulticlassPerceptronClassifier, fit!, predict\n",
    "using LinearAlgebra: mul!\n",
    "using SparseArrays\n",
    "\n",
    "using MLJBase\n",
    "using MLJ\n",
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> needed for classifiers:\n",
    "using CategoricalArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the model struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A model is an object storing hyperparameters associated with some machine learning algorithm. In MLJ, hyperparameters include configuration parameters, like the number of threads, and special instructions, such as \"compute feature rankings\", which may or may not affect the final learning outcome. However, the logging level (verbosity below) is excluded.\n",
    "**\n",
    "\n",
    "\n",
    "In MLJ I would do\n",
    "\n",
    "```\n",
    "mutable struct MulticlassPerceptronClassifier <: MLJBase.Deterministic\n",
    "    n_epochs::Int\n",
    "    epoch_patience::Int\n",
    "    pocket::Bool\n",
    "    average_weights::Bool\n",
    "    element_type::DataType\n",
    "end\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct MulticlassPerceptronClassifier <: MLJBase.Deterministic\n",
    "    n_epochs::Int\n",
    "    epoch_patience::Int\n",
    "    pocket::Bool\n",
    "    average_weights::Bool\n",
    "    element_type::DataType\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "Models (which are mutable) should not be given internal constructors.\n",
    "**\n",
    "\n",
    "**\n",
    "It is recommended that they be given an external lazy keyword constructor of the same name. This constructor defines default values for every field, and optionally corrects invalid field values by calling a clean! method (whose fallback returns an empty message string):\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keyword constructor\n",
    "function MulticlassPerceptronClassifier( ; \n",
    "                                        n_epochs=100,\n",
    "                                        epoch_patience=5,\n",
    "                                        pocket=true,\n",
    "                                        average_weights=true,\n",
    "                                        element_type=Float32)\n",
    "\n",
    "    model = MulticlassPerceptronClassifier(n_epochs,\n",
    "                                           epoch_patience,\n",
    "                                           pocket,\n",
    "                                           average_weights,\n",
    "                                           element_type)\n",
    "    \n",
    "    message = MLJBase.clean!(model)\n",
    "    isempty(message) || @warn message\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function MLJBase.clean is used to change the model hyperparameters in case they are set in an invalid way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function MLJ.clean!(model::MulticlassPerceptronClassifier)\n",
    "    warning = \"\"\n",
    "    if model.n_epochs < 1\n",
    "        warning *= \"Need n_epochs ≥ 1. Resetting n_epochs=100 \"\n",
    "        model.n_epochs = 50\n",
    "    end\n",
    "    \n",
    "    if model.epoch_patience <1\n",
    "        warning *= \"Need epoch_patience ≥ 1. Resetting epoch_patience=5 \"\n",
    "        model.epoch_patience = 5\n",
    "    end\n",
    "    return warning\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct MulticlassPerceptronClassifierParameters{T}\n",
    "    W::AbstractMatrix{T}\n",
    "    b::AbstractVector{T}\n",
    "    n_classes::Int\n",
    "    n_features::Int\n",
    "    is_sparse::Bool\n",
    "end\n",
    "\n",
    "#MulticlassPerceptronClassifierParameters(T::Type, n_classes::Int, n_features::Int) = MulticlassPerceptronClassifierParameters{T}(rand(T, n_features, n_classes),\n",
    "#                                                                                       zeros(T, n_classes),\n",
    "#                                                                                       n_classes,\n",
    "#                                                                                       n_features,\n",
    "#                                                                                       is_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifierParameters"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function MulticlassPerceptronClassifierParameters(T::Type, n_classes::Int, n_features::Int, is_sparse::Bool) \n",
    "    \n",
    "    if is_sparse==false\n",
    "        return MulticlassPerceptronClassifierParameters{T}(rand(T, n_features, n_classes),\n",
    "                                                                                       zeros(T, n_classes),\n",
    "                                                                                       n_classes,\n",
    "                                                                                       n_features,\n",
    "                                                                                       is_sparse)\n",
    "    else\n",
    "        return  MulticlassPerceptronClassifierParameters{T}(sparse(rand(T, n_features, n_classes)),\n",
    "        spzeros(T, n_classes),\n",
    "                                                                                        n_classes,\n",
    "                                                                                        n_features,\n",
    "                                                                                        is_sparse)     \n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_with_placeholder"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Predicts the class for a given input in a `MulticlassPerceptronClassifier`.\n",
    "The placeholder is used to avoid allocating memory for each matrix-vector multiplication.\n",
    "\n",
    "- Returns the predicted class.\n",
    "\"\"\"\n",
    "function predict_with_placeholder(h::MulticlassPerceptronClassifierParameters, x::AbstractVector, class_placeholder::AbstractVector)\n",
    "    #@fastmath class_placeholder .= At_mul_B!(class_placeholder, h.W, x) .+ h.b\n",
    "    class_placeholder .= mul!(class_placeholder, transpose(h.W), x)  .+ h.b\n",
    "    return argmax(class_placeholder)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Compute the accuracy betwwen `y` and `y_hat`.\n",
    "\"\"\"\n",
    "function accuracy(y::AbstractVector, y_hat::AbstractVector)\n",
    "    acc = 0.\n",
    "    @fastmath for k = 1:length(y)\n",
    "            @inbounds  acc += y[k] == y_hat[k]\n",
    "    end\n",
    "    return acc/length(y_hat)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function MLJBase.fit(model::MulticlassPerceptronClassifier,\n",
    "                     verbosity::Int,   \n",
    "                     X,\n",
    "                     y)\n",
    "    \n",
    "    #Xmatrix = MLJBase.matrix(X)\n",
    "    n_classes    = length(unique(y))\n",
    "    classes_seen = unique(y)\n",
    "    n_features   = size(train_x,1)  # this assumes data comes in cols\n",
    "    \n",
    "    #decode  = MLJBase.decoder(y[1]) # for predict method\n",
    "    decode =  false\n",
    "\n",
    "    # Defining the fitpredict object\n",
    "    is_sparse = issparse(X)\n",
    "    perceptron = MulticlassPerceptronClassifierParameters(model.element_type, n_classes, n_features, is_sparse);\n",
    "    \n",
    "    \n",
    "    ### Fitting code starts\n",
    "    fit!(perceptron, X, y; \n",
    "         print_flag=verbosity, \n",
    "         n_epochs=model.n_epochs);\n",
    "    \n",
    "    ### Fitting code ends\n",
    "    cache = nothing\n",
    "    fitresult = (perceptron, decode)\n",
    "    report = NamedTuple{}()\n",
    "    \n",
    "    #> return package-specific statistics (eg, feature rankings,\n",
    "    #> internal estimates of generalization error) in `report`, which\n",
    "    #> should be a named tuple with the same type every call (can have\n",
    "    #> empty values)\n",
    "    \n",
    "    return fitresult, cache, report\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit! (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function fit!(h::MulticlassPerceptronClassifierParameters, X::AbstractArray, y::AbstractVector;\n",
    "              n_epochs=50, \n",
    "              learning_rate=1., \n",
    "              print_flag=0,\n",
    "              compute_accuracy=true, \n",
    "              seed=MersenneTwister(1234),\n",
    "              pocket=false,\n",
    "              shuffle_data=false)\n",
    "    \n",
    "    n_features, n_samples = size(X)\n",
    "    @assert length(y) == n_samples\n",
    "    scores = []\n",
    "    \n",
    "    T = eltype(X)\n",
    "    learning_rate     = T(learning_rate)\n",
    "    class_placeholder = zeros(T, h.n_classes)\n",
    "    y_preds           = zeros(Int64, n_samples)\n",
    "    data_indices      = Array(1:n_samples)\n",
    "    max_acc           = zero(T)\n",
    "\n",
    "    if pocket\n",
    "        W_hat = zeros(T, h.n_features, h.n_classes)\n",
    "        b_hat = zeros(T, h.n_classes)\n",
    "    end\n",
    "\n",
    "    @fastmath for epoch in 1:n_epochs\n",
    "\n",
    "        n_mistakes = 0\n",
    "        if shuffle_data\n",
    "            shuffle!(seed, data_indices)\n",
    "        end\n",
    "        #println(\"\\nepoch \",epoch,\"\\n\")\n",
    "        @inbounds for m in data_indices\n",
    "            #println(\"sample seen \", m ,\"\\n\")\n",
    "            x = view(X, :, m);\n",
    "            #y_hat = predict_with_placeholder(h, x, class_placeholder)\n",
    "            y_hat = argmax(h.W'* x .+ h.b)\n",
    "            \n",
    "            if y[m] != y_hat\n",
    "                n_mistakes += 1\n",
    "                ####  wij ← wij − η (yj −tj) · xi\n",
    "                h.W[:, y[m]]  .= h.W[:, y[m]]  .+ learning_rate .* x\n",
    "                h.b[y[m]]      = h.b[y[m]]     + learning_rate\n",
    "                h.W[:, y_hat] .= h.W[:, y_hat] .- learning_rate .* x\n",
    "                h.b[y_hat]     = h.b[y_hat]    - learning_rate\n",
    "            end\n",
    "        end\n",
    "\n",
    "        #println(\"FINISHED\")\n",
    "\n",
    "        if compute_accuracy\n",
    "             @inbounds for m in  data_indices\n",
    "                 y_preds[m] = predict_with_placeholder(h, view(X, :, m), class_placeholder)\n",
    "            end\n",
    "            acc = accuracy(y, y_preds)\n",
    "            push!(scores, acc)\n",
    "        else\n",
    "            acc = (n_samples - n_mistakes)/n_samples\n",
    "            push!(scores, acc)\n",
    "        end\n",
    "\n",
    "        if pocket\n",
    "            if acc > max_acc\n",
    "                max_acc = acc\n",
    "                copy!(W_hat, h.W)\n",
    "                copy!(b_hat, h.b)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if print_flag ==1\n",
    "            print(\"\\r\\u1b[K\")\n",
    "            print(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        end\n",
    "        \n",
    "        if print_flag ==2\n",
    "            println(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets\n",
    "\n",
    "train_x, train_y = MLDatasets.MNIST.traindata();\n",
    "test_x, test_y   = MLDatasets.MNIST.testdata();\n",
    "train_x          = Float32.(train_x);\n",
    "test_x           = Float32.(test_x);\n",
    "train_y          = train_y .+ 1;\n",
    "test_y           = test_y .+ 1;\n",
    "train_y          = Int64.(train_y);\n",
    "test_y           = Int64.(test_y);\n",
    "train_x          = reshape(train_x, 784, 60000);\n",
    "test_x           = reshape(test_x,  784, 10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 20,\n",
       "                               epoch_patience = 5,\n",
       "                               pocket = true,\n",
       "                               average_weights = true,\n",
       "                               element_type = Float32,)\u001b[34m @ 6…82\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MulticlassPerceptronClassifier(n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 20,\n",
       "                               epoch_patience = 5,\n",
       "                               pocket = true,\n",
       "                               average_weights = true,\n",
       "                               element_type = Float32,)\u001b[34m @ 6…82\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Accuracy: 0.872\n",
      "Epoch: 2 \t Accuracy: 0.872\n",
      "Epoch: 3 \t Accuracy: 0.855\n",
      "Epoch: 4 \t Accuracy: 0.882\n",
      "Epoch: 5 \t Accuracy: 0.88\n",
      "Epoch: 6 \t Accuracy: 0.871\n",
      "Epoch: 7 \t Accuracy: 0.893\n",
      "Epoch: 8 \t Accuracy: 0.889\n",
      "Epoch: 9 \t Accuracy: 0.88\n",
      "Epoch: 10 \t Accuracy: 0.875\n",
      "Epoch: 11 \t Accuracy: 0.884\n",
      "Epoch: 12 \t Accuracy: 0.871\n",
      "Epoch: 13 \t Accuracy: 0.867\n",
      "Epoch: 14 \t Accuracy: 0.887\n",
      "Epoch: 15 \t Accuracy: 0.879\n",
      "Epoch: 16 \t Accuracy: 0.886\n",
      "Epoch: 17 \t Accuracy: 0.884\n",
      "Epoch: 18 \t Accuracy: 0.894\n",
      "Epoch: 19 \t Accuracy: 0.869\n",
      "Epoch: 20 \t Accuracy: 0.874\n"
     ]
    }
   ],
   "source": [
    "fitresult, _ , _  = MLJBase.fit(model, 2, train_x, train_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a predict\n",
    "\n",
    "In order to predict in MLJ we need 3 things.\n",
    "\n",
    "- The model (abstract model definition with hyperparameters)\n",
    "- The fitresult of the model (containing the learned parameters of the model)\n",
    "- Data\n",
    "\n",
    "\n",
    "#### Example of predict for an SVMC\n",
    "\n",
    "The following code is for predicting with a sklearn SVMC\n",
    "\n",
    "```\n",
    "function MLJBase.predict(model::SVMC\n",
    "                         , fitresult\n",
    "                         , Xnew)\n",
    "\n",
    "    xnew = MLJBase.matrix(Xnew)\n",
    "    result, decode = fitresult\n",
    "    prediction = ScikitLearn.predict(result, xnew)\n",
    "    return decode(prediction)\n",
    "end\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(h::MulticlassPerceptronClassifierParameters, x::AbstractVector, class_placeholder::AbstractVector)\n",
    "    class_placeholder .= mul!(class_placeholder, transpose(h.W), x)  .+ h.b\n",
    "    return argmax(class_placeholder)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function to predict the class for a given input batch.\n",
    "- Returns the predicted class.\n",
    "\"\"\"\n",
    "function predict(h::MulticlassPerceptronClassifierParameters, X::AbstractMatrix)\n",
    "    predictions = zeros(Int64, size(X, 2))\n",
    "    class_placeholder = zeros(eltype(h.W), h.n_classes)\n",
    "\n",
    "    @inbounds for m in 1:length(predictions)\n",
    "        predictions[m] = predict(h, view(X,:,m), class_placeholder)\n",
    "    end\n",
    "    \n",
    "    return predictions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "function MLJBase.predict(model::MulticlassPerceptronClassifier, fitresult, Xnew)\n",
    "    xnew = MLJBase.matrix(Xnew)\n",
    "    result, decode = fitresult\n",
    "    prediction = predict(result, xnew)\n",
    "    return prediction #decode(prediction)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Array{Int64,1}:\n",
       "  6\n",
       "  1\n",
       "  5\n",
       "  2\n",
       " 10\n",
       "  3\n",
       "  2\n",
       "  4\n",
       "  2\n",
       "  5\n",
       "  4\n",
       "  6\n",
       "  4\n",
       "  7\n",
       "  2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLJBase.predict(model,fitresult,train_x[:,1:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Allowing fit(model,X,y) with categorical arrays\n",
    "\n",
    "\n",
    "Assume that the data is given with a categorical label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "catname = Dict(1 => \"one\",\n",
    "               2 => \"two\",\n",
    "               3 => \"three\",\n",
    "               4 => \"four\",\n",
    "               5 => \"five\",\n",
    "               6 => \"six\",\n",
    "               7 => \"seven\",\n",
    "               8 => \"eight\",\n",
    "               9 => \"nine\",\n",
    "               10 => \"ten\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_labels = [catname[i] for i in train_y];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us imagine that we are given the data in the following format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{String,1}:\n",
       " \"six\" \n",
       " \"one\" \n",
       " \"five\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_labels[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we should, before we fit any model, take care of rewritting classes as numbers from 1 to N.\n",
    "\n",
    "We can make our MLJ model do this automatically inside the `fit` method as long as we provide `train_y_labels`  as a CategoricalArray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_cat = CategoricalArray(train_y_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CategoricalArray{String,1,UInt32}:\n",
       " \"six\"  \n",
       " \"one\"  \n",
       " \"five\" \n",
       " \"two\"  \n",
       " \"ten\"  \n",
       " \"three\"\n",
       " \"two\"  \n",
       " \"four\" \n",
       " \"two\"  \n",
       " \"five\" "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_cat[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A categorical array will contain\n",
    "\n",
    "- `x.pool` all possible categories found.\n",
    "- `x.refs` each value of the array encoded as a refenrence to an element in the pool.\n",
    "- `levels(x)` returns the possible levels (categories) of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(train_y_cat.pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalPool{String,UInt32}([\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"ten\",\"three\",\"two\"])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_cat.pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalArray{String,1,UInt32}:\n",
       " \"six\" \n",
       " \"one\" \n",
       " \"five\"\n",
       " \"two\" \n",
       " \"ten\" "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_cat[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{UInt32,1}:\n",
       " 0x00000001\n",
       " 0x00000002\n",
       " 0x00000003\n",
       " 0x00000004\n",
       " 0x00000005"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_cat.refs[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{UInt32,1}:\n",
       " 0x00000007\n",
       " 0x00000005\n",
       " 0x00000002\n",
       " 0x0000000a\n",
       " 0x00000008"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(train_y_cat[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to map from numbers back to strings we need a decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJBase.CategoricalDecoder{String,UInt32}(CategoricalPool{String,UInt32}([\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"ten\",\"three\",\"two\"]), [9, 3, 7, 10, 2, 8, 1, 5, 6, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = decoder(train_y_cat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalArray{String,1,UInt32}:\n",
       " \"six\" \n",
       " \"one\" \n",
       " \"five\"\n",
       " \"two\" \n",
       " \"ten\" "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(int(train_y_cat[1:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalString{UInt32} \"two\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all ingrediets to create\n",
    "\n",
    "`MLJBase.fit(model::MulticlassPerceptronClassifier, verbosity,X,y)`\n",
    "\n",
    "Which takes as input `y` a Categorical array and does the following:\n",
    "\n",
    "- Takes a single element from the categorical array (which stores all possible class labels) and from this element it creates  a decoding function that, given an integer it returns back a category. \n",
    "\n",
    "```julia\n",
    "    # decoder maps Integer->Category, used in the predict method\n",
    "    decode  = MLJBase.decoder(y[1]) \n",
    "```\n",
    "\n",
    "\n",
    "- It maps the categorical array to integers:\n",
    "```julia\n",
    "   # Encodes CategoricalArray to an Array of integers\n",
    "   y = Int.(int(y))  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function MLJBase.fit(model::MulticlassPerceptronClassifier,\n",
    "                     verbosity::Int,   \n",
    "                     X,\n",
    "                     y)\n",
    "    \n",
    "    #Xmatrix = MLJBase.matrix(X)\n",
    "    n_classes    = length(unique(y))\n",
    "    classes_seen = unique(y)\n",
    "    n_features   = size(X,1)  # this assumes data comes in cols\n",
    "\n",
    "    decode  = MLJBase.decoder(y[1]) # for predict method\n",
    "    \n",
    "    y = Int.(int(y))  # Encoding my categorical array to an array of integers\n",
    "\n",
    "    is_sparse = issparse(X)\n",
    "    perceptron = MulticlassPerceptronClassifierParameters(model.element_type, n_classes, n_features, is_sparse);\n",
    "\n",
    "    ### Fitting code starts\n",
    "    fit!(perceptron, X, y; \n",
    "         print_flag=verbosity, \n",
    "         n_epochs=model.n_epochs);\n",
    "    \n",
    "    ### Fitting code ends\n",
    "    cache = nothing\n",
    "    fitresult = (perceptron, decode)\n",
    "    report = NamedTuple{}()\n",
    "    \n",
    "    #> return package-specific statistics (eg, feature rankings,\n",
    "    #> internal estimates of generalization error) in `report`, which\n",
    "    #> should be a named tuple with the same type every call (can have\n",
    "    #> empty values)\n",
    "    return fitresult, cache, report\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 5,\n",
       "                               epoch_patience = 5,\n",
       "                               pocket = true,\n",
       "                               average_weights = true,\n",
       "                               element_type = Float32,)\u001b[34m @ 1…83\u001b[39m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MulticlassPerceptronClassifier(n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Accuracy: 0.872\n",
      "Epoch: 2 \t Accuracy: 0.88\n",
      "Epoch: 3 \t Accuracy: 0.884\n",
      "Epoch: 4 \t Accuracy: 0.884\n",
      "Epoch: 5 \t Accuracy: 0.88\n",
      "  1.741249 seconds (4.26 M allocations: 405.762 MiB, 5.18% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((MulticlassPerceptronClassifierParameters{Float32}(Float32[0.73096 0.0342447 … 0.669984 0.208333; 0.612626 0.413586 … 0.994569 0.0856211; … ; 0.0386736 0.179588 … 0.637083 0.953892; 0.912965 0.834118 … 0.531651 0.308105], Float32[49.0, -4.0, -20.0, -88.0, -45.0, -26.0, 100.0, -14.0, 18.0, 30.0], 10, 784, false), MLJBase.CategoricalDecoder{String,UInt32}(CategoricalPool{String,UInt32}([\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"ten\",\"three\",\"two\"]), [9, 3, 7, 10, 2, 8, 1, 5, 6, 4])), nothing, NamedTuple())"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time fitresult, _ , _  = MLJBase.fit(model, 2, train_x, train_y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJBase.CategoricalDecoder{String,UInt32}(CategoricalPool{String,UInt32}([\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"ten\",\"three\",\"two\"]), [9, 3, 7, 10, 2, 8, 1, 5, 6, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = fitresult[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalString{UInt32} \"five\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "function MLJBase.predict(model::MulticlassPerceptronClassifier, fitresult, Xnew)\n",
    "    xnew = MLJBase.matrix(Xnew)\n",
    "    result, decode = fitresult\n",
    "    prediction = predict(result, xnew)\n",
    "    return decode(prediction)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element CategoricalArray{String,1,UInt32}:\n",
       " \"six\" \n",
       " \"one\" \n",
       " \"five\"\n",
       " \"two\" "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLJBase.predict(model, fitresult, train_x[:,1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction types for deterministic responses.\n",
    "\n",
    "In the case of Deterministic models, yhat should be an AbstractVector (commonly a plain Vector) with the same element type as the target y passed to the fit method (see above). Any CategoricalValue or CategoricalString appearing in yhat must have the same levels in its pool as was present in the elements of the target y presented in training, even if not all levels appear in the training data or prediction itself. For example, in the univariate target case, this means MLJ.classes(yhat[i]) = MLJ.classes(y[j]) for all admissible i and j. (The method classes is described under Convenience methods below).\n",
    "\n",
    "Unfortunately, code not written with the preservation of categorical levels in mind poses special problems. To help with this, MLJBase provides three utility methods: int (for converting a CategoricalValue or CategoricalString into an integer, the ordering of these integers being consistent with that of the pool), decoder (for constructing a callable object that decodes the integers back into CategoricalValue/CategoricalString objects), and classes, for extracting the complete pool from a single value. Refer to Convenience methods below for important details.\n",
    "\n",
    "Note that a decoder created during fit may need to be bundled with fitresult to make it available to predict during re-encoding. So, for example, if the core algorithm being wrapped by fit expects a nominal target yint of type Vector{<:Integer} then a fit method may look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sparse data\n",
    "\n",
    "Let us load a dataset with text data and let's build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{String,1}:\n",
       " \"@\"      \n",
       " \"@v#.#\"  \n",
       " \"@stdlib\"\n",
       " \"./\"     "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push!(LOAD_PATH, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling AmazonBookReviews [top-level]\n",
      "└ @ Base loading.jl:1186\n"
     ]
    }
   ],
   "source": [
    "using AmazonBookReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#;open AmazonBookReviews.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min support:5"
     ]
    }
   ],
   "source": [
    "word_to_pos, pos_to_word, supported_word_counts, (X,y) =   AmazonBookReviews.load_data();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13195, 2000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features, n_samples = size(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_sparsity (generic function with 1 method)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_sparsity(X)\n",
    "    n_features, n_samples = size(X)\n",
    "    m = 0\n",
    "    for i in 1:n_samples\n",
    "        m += sum(view(X,:,i))\n",
    "    end\n",
    "    mean_words_found = m/n_samples\n",
    "    return mean_words_found, 100 * mean_words_found/n_features\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156.7f0, 1.187571f0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling MLDataUtils [cc2ba9b6-d476-5e6d-8eaf-a92d5412d41d]\n",
      "└ @ Base loading.jl:1186\n"
     ]
    }
   ],
   "source": [
    "using MLDataUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_tr, y_tr), (X_te, y_te) = stratifiedobs((X, y), p = 0.7);\n",
    "\n",
    "X_tr = copy(X_tr)\n",
    "y_tr = copy(y_tr)\n",
    "X_te = copy(X_te)\n",
    "y_te = copy(y_te);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13195, 1400), (13195, 600))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(X_tr), size(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the matrices are not sparse.\n",
    "\n",
    "We can use `SparseArrays` to encode them as sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_sp = sparse(X_tr)\n",
    "X_te_sp = sparse(X_te);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.967056 seconds (290.88 k allocations: 287.597 MiB, 11.40% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time X_tr_sp * X_tr_sp';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.953984 seconds (925.79 k allocations: 708.424 MiB, 6.57% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time X_tr * X_tr';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the MulticlassPerceptron with sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_cat = CategoricalArray(y_tr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13195, 1400), (1400,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(X_tr_sp), size(y_tr_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 50,\n",
       "                               epoch_patience = 5,\n",
       "                               pocket = true,\n",
       "                               average_weights = true,\n",
       "                               element_type = Float32,)\u001b[34m @ 1…34\u001b[39m"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MulticlassPerceptronClassifier(n_epochs=50, element_type=Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KEpoch: 50 \t Accuracy: 1.0  1.115667 seconds (1.03 M allocations: 140.465 MiB, 2.70% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((MulticlassPerceptronClassifierParameters{Float32}(Float32[0.0259023 0.581819; 0.646623 0.49239; … ; 2.35888 -1.26332; 2.13371 -1.57738], Float32[-3.0, 3.0], 2, 13195, false), MLJBase.CategoricalDecoder{Float64,UInt32}(CategoricalPool{Float64,UInt32}([-1.0,1.0]), [1, 2])), nothing, NamedTuple())"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time fitresult, _ , _  = MLJBase.fit(model, 1, X_tr, y_tr_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "affine_dense_input_sparse (generic function with 1 method)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function affine_dense_input_sparse(W_dense, b_dense, x_sp)\n",
    "    n_rows_W, n_cols_W = size(W_dense)\n",
    "    result = zeros(eltype(W_dense), n_rows_W)\n",
    "    \n",
    "    \n",
    "    @inbounds for j in 1:n_rows_W\n",
    "        for i in x_sp.nzind\n",
    "            result[j] += W_dense[j,i] * x_sp[i] \n",
    "        end\n",
    "        result[j] +=  b_dense[j]\n",
    "    end\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit! (generic function with 1 method)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function fit!(h::MulticlassPerceptronClassifierParameters, X::AbstractArray, y::AbstractVector;\n",
    "              n_epochs=50, \n",
    "              learning_rate=1., \n",
    "              print_flag=0,\n",
    "              compute_accuracy=false, \n",
    "              seed=MersenneTwister(1234),\n",
    "              pocket=false,\n",
    "              shuffle_data=false)\n",
    "    \n",
    "    n_features, n_samples = size(X)\n",
    "    @assert length(y) == n_samples\n",
    "    scores = []\n",
    "    \n",
    "    T = eltype(X)\n",
    "    learning_rate     = T(learning_rate)\n",
    "    class_placeholder = zeros(T, h.n_classes)\n",
    "    y_preds           = zeros(Int64, n_samples)\n",
    "    data_indices      = Array(1:n_samples)\n",
    "    max_acc           = zero(T)\n",
    "\n",
    "    if pocket\n",
    "        W_hat = zeros(T, h.n_features, h.n_classes)\n",
    "        b_hat = zeros(T, h.n_classes)\n",
    "    end\n",
    "\n",
    "    for epoch in 1:n_epochs\n",
    "\n",
    "        n_mistakes = 0\n",
    "        if shuffle_data\n",
    "            shuffle!(seed, data_indices)\n",
    "        end\n",
    "        #println(\"\\nepoch \",epoch,\"\\n\")\n",
    "        @inbounds for m in data_indices\n",
    "            #println(\"sample seen \", m ,\"\\n\")\n",
    "            #@btime x = view($X, :, $m);\n",
    "            #x = view(X, :, m);\n",
    "            x = X[:, m]\n",
    "            #x = view(X_tr_sp.rowval, X_tr_sp.colptr[2]:(X_tr_sp.colptr[3]-1 ))\n",
    "            #x = view(X_tr_sp.rowval, X_tr_sp.colptr[m]:(X_tr_sp.colptr[m]-1 ))\n",
    "\n",
    "\n",
    "            #y_hat = predict_with_placeholder(h, x, class_placeholder)\n",
    "            #@btime y_hat = argmax($h.W'* $x .+ $h.b)W\n",
    "            #y_hat = argmax(h.W'* x + h.b)\n",
    "            y_hat = argmax(affine_dense_input_sparse(h.W', h.b, x))\n",
    "            y_m = y[m]\n",
    "            #break ############# REMOVE\n",
    "            if y_m != y_hat\n",
    "                n_mistakes += 1\n",
    "                ####  wij ← wij − η (yj −tj) · xi\n",
    "                h.W[:, y_m]  .= h.W[:, y_m]  + learning_rate .* x\n",
    "                h.b[y_m]      = h.b[y_m]     + learning_rate\n",
    "                h.W[:, y_hat] .= h.W[:, y_hat] - learning_rate .* x\n",
    "                h.b[y_hat]     = h.b[y_hat]    - learning_rate\n",
    "            end\n",
    "        end\n",
    "        #break ############# REMOVE\n",
    "        #println(\"FINISHED\")\n",
    "\n",
    "        if compute_accuracy\n",
    "             @inbounds for m in  data_indices\n",
    "                 #y_preds[m] = predict_with_placeholder(h, view(X, :, m), class_placeholder)\n",
    "                y_preds[m] = predict_with_placeholder(h, X[:,m], class_placeholder)\n",
    "            end\n",
    "            acc = accuracy(y, y_preds)\n",
    "            push!(scores, acc)\n",
    "        else\n",
    "            acc = (n_samples - n_mistakes)/n_samples\n",
    "            push!(scores, acc)\n",
    "        end\n",
    "\n",
    "        if pocket\n",
    "            if acc > max_acc\n",
    "                max_acc = acc\n",
    "                copy!(W_hat, h.W)\n",
    "                copy!(b_hat, h.b)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if print_flag ==1\n",
    "            print(\"\\r\\u1b[K\")\n",
    "            print(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        end\n",
    "        \n",
    "        if print_flag ==2\n",
    "            println(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 50,\n",
       "                               epoch_patience = 5,\n",
       "                               pocket = true,\n",
       "                               average_weights = true,\n",
       "                               element_type = Float32,)\u001b[34m @ 1…41\u001b[39m"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MulticlassPerceptronClassifier(n_epochs=50, element_type=Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KEpoch: 50 \t Accuracy: 1.0  4.902879 seconds (1.34 M allocations: 785.255 MiB, 2.26% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time fitresult, _ , _  = MLJBase.fit(model, 1, X_tr_sp, y_tr_cat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to avoid creating the col vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  230.146 ns (2 allocations: 80 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime view(X_tr_sp.rowval, X_tr_sp.colptr[2]:(X_tr_sp.colptr[3]-1 ));            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  482.732 ns (2 allocations: 64 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime  view(X_tr_sp, :, 2);   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.0f0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(view(X_tr_sp, :, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: m not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: m not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[79]:1"
     ]
    }
   ],
   "source": [
    "x_m_beg = X_tr_sp.colptr[m]\n",
    "x_m_end = X_tr_sp.colptr[m+1] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: x_m_beg not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: x_m_beg not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[80]:1"
     ]
    }
   ],
   "source": [
    "X_tr_sp.rowval[x_m_beg:x_m_end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "affine_dense_input_sparse (generic function with 2 methods)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function affine_dense_input_sparse(W_dense, b_dense, X, x_m_beg, x_m_end)\n",
    "    n_rows_W, n_cols_W = size(W_dense)\n",
    "    result = zeros(eltype(W_dense), n_rows_W)\n",
    "    \n",
    "    @inbounds for j in 1:n_rows_W\n",
    "        for i in X.rowval[x_m_beg:x_m_end]\n",
    "            result[j] += W_dense[j,i] * X.nzval[i] \n",
    "        end\n",
    "        result[j] +=  b_dense[j]\n",
    "    end\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit! (generic function with 1 method)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function fit!(h::MulticlassPerceptronClassifierParameters, X::AbstractArray, y::AbstractVector;\n",
    "              n_epochs=50, \n",
    "              learning_rate=1., \n",
    "              print_flag=0,\n",
    "              compute_accuracy=false, \n",
    "              seed=MersenneTwister(1234),\n",
    "              pocket=false,\n",
    "              shuffle_data=false)\n",
    "    \n",
    "    n_features, n_samples = size(X)\n",
    "    @assert length(y) == n_samples\n",
    "    scores = []\n",
    "    \n",
    "    T = eltype(X)\n",
    "    learning_rate     = T(learning_rate)\n",
    "    class_placeholder = zeros(T, h.n_classes)\n",
    "    y_preds           = zeros(Int64, n_samples)\n",
    "    data_indices      = Array(1:n_samples)\n",
    "    max_acc           = zero(T)\n",
    "\n",
    "    if pocket\n",
    "        W_hat = zeros(T, h.n_features, h.n_classes)\n",
    "        b_hat = zeros(T, h.n_classes)\n",
    "    end\n",
    "\n",
    "    for epoch in 1:n_epochs\n",
    "\n",
    "        n_mistakes = 0\n",
    "        if shuffle_data\n",
    "            shuffle!(seed, data_indices)\n",
    "        end\n",
    "        #println(\"\\nepoch \",epoch,\"\\n\")\n",
    "        @inbounds for m in data_indices\n",
    "            #x = X[:, m]\n",
    "        \n",
    "            x_m_beg = X.colptr[m]\n",
    "            x_m_end = X.colptr[m+1] -1\n",
    "            y_hat = argmax(affine_dense_input_sparse(h.W', h.b, X, x_m_beg, x_m_end))\n",
    "            y_m = y[m]\n",
    "\n",
    "            #break ############# REMOVE\n",
    "            if y_m != y_hat\n",
    "                n_mistakes += 1\n",
    "                ####  wij ← wij − η (yj −tj) · xi\n",
    "                for i in X.rowval[x_m_beg:x_m_end]\n",
    "                    \n",
    "                    #h.W[:, y_m]  .= h.W[:, y_m]  + learning_rate .* x\n",
    "                    h.W[i, y_m]   +=  learning_rate * X.nzval[i]\n",
    "                    \n",
    "                    #h.W[:, y_hat] .= h.W[:, y_hat] - learning_rate .* x\n",
    "                    h.W[i, y_hat] -=  learning_rate * X.nzval[i]\n",
    "                end\n",
    "                h.b[y_m]      = h.b[y_m]     + learning_rate\n",
    "                h.b[y_hat]    = h.b[y_hat]    - learning_rate\n",
    "            end\n",
    "        end\n",
    "        #break ############# REMOVE\n",
    "        #println(\"FINISHED\")\n",
    "\n",
    "        if compute_accuracy\n",
    "             @inbounds for m in  data_indices\n",
    "                 #y_preds[m] = predict_with_placeholder(h, view(X, :, m), class_placeholder)\n",
    "                y_preds[m] = predict_with_placeholder(h, X[:,m], class_placeholder)\n",
    "            end\n",
    "            acc = accuracy(y, y_preds)\n",
    "            push!(scores, acc)\n",
    "        else\n",
    "            acc = (n_samples - n_mistakes)/n_samples\n",
    "            push!(scores, acc)\n",
    "        end\n",
    "\n",
    "        if pocket\n",
    "            if acc > max_acc\n",
    "                max_acc = acc\n",
    "                copy!(W_hat, h.W)\n",
    "                copy!(b_hat, h.b)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if print_flag ==1\n",
    "            print(\"\\r\\u1b[K\")\n",
    "            print(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        end\n",
    "        \n",
    "        if print_flag ==2\n",
    "            println(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 50,\n",
       "                               epoch_patience = 5,\n",
       "                               pocket = true,\n",
       "                               average_weights = true,\n",
       "                               element_type = Float32,)\u001b[34m @ 1…02\u001b[39m"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MulticlassPerceptronClassifier(n_epochs=50, element_type=Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KEpoch: 50 \t Accuracy: 1.0  1.345 s (1415513 allocations: 179.10 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime fitresult, _ , _  = MLJBase.fit(model, 1, X_tr_sp, y_tr_cat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime fitresult, _ , _  = MLJBase.fit(model, 1, X_tr_sp, y_tr_cat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@time fitresult[1].W' * X_tr_sp[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making matvecprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function fit!(h::MulticlassPerceptronClassifierParameters, X::AbstractArray, y::AbstractVector;\n",
    "              n_epochs=50, \n",
    "              learning_rate=1., \n",
    "              print_flag=0,\n",
    "              compute_accuracy=true, \n",
    "              seed=MersenneTwister(1234),\n",
    "              pocket=false,\n",
    "              shuffle_data=false)\n",
    "    \n",
    "    n_features, n_samples = size(X)\n",
    "    @assert length(y) == n_samples\n",
    "    scores = []\n",
    "    \n",
    "    T = eltype(X)\n",
    "    learning_rate     = T(learning_rate)\n",
    "    class_placeholder = zeros(T, h.n_classes)\n",
    "    y_preds           = zeros(Int64, n_samples)\n",
    "    data_indices      = Array(1:n_samples)\n",
    "    max_acc           = zero(T)\n",
    "\n",
    "    if pocket\n",
    "        W_hat = zeros(T, h.n_features, h.n_classes)\n",
    "        b_hat = zeros(T, h.n_classes)\n",
    "    end\n",
    "\n",
    "    for epoch in 1:n_epochs\n",
    "\n",
    "        n_mistakes = 0\n",
    "        if shuffle_data\n",
    "            shuffle!(seed, data_indices)\n",
    "        end\n",
    "        #println(\"\\nepoch \",epoch,\"\\n\")\n",
    "        @inbounds for m in data_indices\n",
    "            #println(\"sample seen \", m ,\"\\n\")\n",
    "            #@btime x = view($X, :, $m);\n",
    "            #x = view(X, :, m);\n",
    "            x = X[:, m]\n",
    "            #y_hat = predict_with_placeholder(h, x, class_placeholder)\n",
    "            #@btime y_hat = argmax($h.W'* $x .+ $h.b)\n",
    "            y_hat = argmax(h.W'* x + h.b)\n",
    "            y_m = y[m]\n",
    "            #break ############# REMOVE\n",
    "            if y_m != y_hat\n",
    "                n_mistakes += 1\n",
    "                ####  wij ← wij − η (yj −tj) · xi\n",
    "                h.W[:, y_m]  .= h.W[:, y_m]  + learning_rate .* x\n",
    "                h.b[y_m]      = h.b[y_m]     + learning_rate\n",
    "                h.W[:, y_hat] .= h.W[:, y_hat] - learning_rate .* x\n",
    "                h.b[y_hat]     = h.b[y_hat]    - learning_rate\n",
    "            end\n",
    "        end\n",
    "        #break ############# REMOVE\n",
    "        #println(\"FINISHED\")\n",
    "\n",
    "        if compute_accuracy\n",
    "             @inbounds for m in  data_indices\n",
    "                 #y_preds[m] = predict_with_placeholder(h, view(X, :, m), class_placeholder)\n",
    "                y_preds[m] = predict_with_placeholder(h, X[:,m], class_placeholder)\n",
    "            end\n",
    "            acc = accuracy(y, y_preds)\n",
    "            push!(scores, acc)\n",
    "        else\n",
    "            acc = (n_samples - n_mistakes)/n_samples\n",
    "            push!(scores, acc)\n",
    "        end\n",
    "\n",
    "        if pocket\n",
    "            if acc > max_acc\n",
    "                max_acc = acc\n",
    "                copy!(W_hat, h.W)\n",
    "                copy!(b_hat, h.b)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if print_flag ==1\n",
    "            print(\"\\r\\u1b[K\")\n",
    "            print(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        end\n",
    "        \n",
    "        if print_flag ==2\n",
    "            println(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MulticlassPerceptronClassifier(n_epochs=2, element_type=Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile fitresult, _ , _  = MLJBase.fit(model, 2, X_tr_sp, y_tr_cat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TimerOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the speed of fitting: Why is it so slow with sparse data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Wsp = sparse(fitresult[1].W);\n",
    "b = fitresult[1].b\n",
    "x_sp = X_tr_sp[:,1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime $Wsp'* $x_sp + $b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@btime dense_weights_vector_sparse($Wsp',$b, $x_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime fitresult[1].W' * X_tr_sp[:,1] + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@btime fitresult[1].W' * X_tr_sp[:,1] + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making our own matrix vector product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(fitresult[1].W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = fitresult[1].W';\n",
    "b = fitresult[1].b\n",
    "x_sp = X_tr_sp[:,1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "function dense_weights_vector_sparse(W_dense,b_dense, x_sp)\n",
    "    n_rows_W, n_cols_W = size(W_dense)\n",
    "    result = zeros(eltype(W_dense), n_rows_W)\n",
    "    \n",
    "    @inbounds for j in 1:n_rows_W\n",
    "        for i in x_sp.nzind\n",
    "            result[j] += W_dense[j,i] * x_sp[i] \n",
    "        end\n",
    "        result[j] +=  b[j]\n",
    "    end\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_weights_vector_sparse(W,b, x_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W * x_sp + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime W*x_sp + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime dense_weights_vector_sparse(W,b, x_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Array(x)\n",
    "W = Array(W)\n",
    "W_sp = sparse(W);\n",
    "b_sp = fitresult[1].b;\n",
    "b    = Array(fitresult[1].b)\n",
    "aux  = zeros(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime W_sp * x_sp + b_sp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime mul!(aux, W_sp, x_sp) + b_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime mul!(aux, W_sp, x_sp) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime W_sp*x_sp + b_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime W *x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime W *x_sp + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime mul!(aux, W_sp, x_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime mul!(aux, W_sp, x_sp) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix vector mutliply faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dense_vector_sparse(fitresult[1].W',aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime fitresult[1].W' * aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime matrix_dense_vector_sparse(fitresult[1].W',aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issparse(X_tr_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_X = typeof(X_tr_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

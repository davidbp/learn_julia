{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPUArrays in julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTIONS\n",
    "\n",
    "- How do we list all possible openCL devices? cpus and gpus?\n",
    "- How do we select a particular device, send an array there and make an operation\n",
    "- How do we check at anytime, how much memory is on a device:\n",
    "    - In this example if  `A_mul_B!(X_result, X, X)` is done using bigger matrices OSX becomes completly unusable (the graphical user interface). We should use the GPU that is not beeing used for the graphical user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GPUArrays\n",
    "using CLArrays\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 500\n",
    "X = rand(Float32,s,s);\n",
    "X_result = zeros(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping arrays to devices\n",
    "\n",
    "Let `X` be an array. When doing  `X_gpu = GPUArray(X)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gpu = GPUArrays.JLArray(X);\n",
    "X_result_gpu = GPUArrays.JLArray(zeros(Float32,500,500));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gpu.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times\n",
      "size: 100 x 100 seconds: 8.138e-5 seconds\n",
      "size: 600 x 600 seconds: 0.005215154 seconds\n",
      "size: 1100 x 1100 seconds: 0.025084941 seconds\n",
      "size: 1600 x 1600 seconds: 0.071604935 seconds\n",
      "size: 2100 x 2100 seconds: 0.165592458 seconds\n",
      "size: 2600 x 2600 seconds: 0.313047113 seconds\n",
      "size: 3100 x 3100 seconds: 0.529375186 seconds\n",
      "size: 3600 x 3600 seconds: 0.832789605 seconds\n",
      "\n",
      "GPU times\n",
      "size: 100 x 100 seconds: 3.9666e-5 seconds\n",
      "size: 600 x 600 seconds: 3.5773e-5 seconds\n",
      "size: 1100 x 1100 seconds: 5.2693e-5 seconds\n",
      "size: 1600 x 1600 seconds: 7.8384e-5 seconds\n",
      "size: 2100 x 2100 seconds: 8.7341e-5 seconds\n",
      "size: 2600 x 2600 seconds: 8.2634e-5 seconds\n",
      "size: 3100 x 3100 seconds: 6.0159e-5 seconds\n",
      "size: 3600 x 3600 seconds: 0.000168922 seconds\n"
     ]
    }
   ],
   "source": [
    "sizes = [x for x in 100:500:4000];\n",
    "cpu_times = Dict()\n",
    "gpu_times = Dict()\n",
    "\n",
    "println(\"\\nCPU times\")\n",
    "for s in sizes\n",
    "    X = rand(Float32,s,s);\n",
    "    X_result = zeros(X);\n",
    "    res_cpu = @elapsed A_mul_B!(X_result, X,X)\n",
    "    println(\"size: \", s, \" x \", s, \" seconds: \", res_cpu, \" seconds\")\n",
    "    #cpu_times[s] = mean(res_cpu.times)/10^6\n",
    "end\n",
    "\n",
    "println(\"\\nGPU times\")\n",
    "for s in sizes\n",
    "    X = rand(Float32,s,s);\n",
    "    X_result = zeros(X);\n",
    "    X_gpu = CLArray(X);\n",
    "    X_result_gpu =  CLArray(zeros(Float32,s,s));\n",
    "\n",
    "    res_gpu = @elapsed A_mul_B!(X_result_gpu, X_gpu, X_gpu)\n",
    "    println(\"size: \", s, \" x \", s, \" seconds: \", res_gpu, \" seconds\")\n",
    "    #gpu_times[s] = mean(res_gpu.times)/10^6\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing a device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLBackend.init(device_type=:gpu,device_idx=1)  ### How do we seelct a particular GPU?\n",
    "#CLBackend.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using CLBLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "gemm!(tA, tB, alpha, A, B, beta, C)\n",
       "```\n",
       "\n",
       "Update `C` as `alpha*A*B + beta*C` or the other three variants according to [`tA`](@ref stdlib-blas-trans) and `tB`. Returns the updated `C`.\n"
      ],
      "text/plain": [
       "```\n",
       "gemm!(tA, tB, alpha, A, B, beta, C)\n",
       "```\n",
       "\n",
       "Update `C` as `alpha*A*B + beta*C` or the other three variants according to [`tA`](@ref stdlib-blas-trans) and `tB`. Returns the updated `C`.\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?CLBLAS.gemm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     868.350 ms (0.00% GC)\n",
       "  median time:      875.972 ms (0.00% GC)\n",
       "  mean time:        878.634 ms (0.00% GC)\n",
       "  maximum time:     890.103 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          6\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since alpha=1., beta=0 this is doing C = A * B  \n",
    "@benchmark CLBLAS.gemm!('N', 'N', Float32(1.0), X_gpu, X_gpu, Float32(0.0), X_result_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mul_B!(X_result, X, X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isapprox(Array(X_result_gpu), X_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: free not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: free not defined\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "free(X_gpu), free(X_result_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking array operations\n",
    "\n",
    "We can use functions such `A_mul_B!` with `GPUArray` objects.  Multiple dispatch will take care of using the targeted GPU.\n",
    "\n",
    "- A_mul_B!\n",
    "- A_mul_Bc!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gpu = CLArray(X);\n",
    "X_result_gpu = similar(X_gpu);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     884.468 ms (0.00% GC)\n",
       "  median time:      903.473 ms (0.00% GC)\n",
       "  mean time:        906.247 ms (0.00% GC)\n",
       "  maximum time:     938.804 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          6\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark A_mul_B!(X_result, X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.30 KiB\n",
       "  allocs estimate:  96\n",
       "  --------------\n",
       "  minimum time:     13.674 μs (0.00% GC)\n",
       "  median time:      14.674 μs (0.00% GC)\n",
       "  mean time:        17.124 μs (4.41% GC)\n",
       "  maximum time:     16.526 ms (45.69% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark A_mul_B!(X_result_gpu, X_gpu, X_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isapprox(Array(X_result_gpu), X_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking A_mul_B! for different sizes\n",
    "\n",
    "Notice that a microseconds (μ) is one milionth of a second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes = [x for x in 100:100:400];\n",
    "cpu_times = Dict()\n",
    "gpu_times = Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in sizes\n",
    "    X = rand(Float32,s,s);\n",
    "    X_result = zeros(X);\n",
    "\n",
    "    X_gpu = GPUArray(X);\n",
    "    X_result_gpu = GPUArray(zeros(Float32,s,s));\n",
    "    \n",
    "    res_cpu = @benchmark A_mul_B!(X_result, X,X)\n",
    "    res_gpu = @benchmark A_mul_B!(X_result_gpu, X_gpu, X_gpu)\n",
    "    \n",
    "    println(\"\\nsize: \", s, \" x \", s)\n",
    "    println(\"\\t cpu mean time taken: \", mean(res_cpu.times)/10^6, \" seconds\")\n",
    "    println(\"\\t gpu mean time taken: \", mean(res_gpu.times)/10^6, \" seconds\")\n",
    "    cpu_times[s] = mean(res_cpu.times)/10^6\n",
    "    gpu_times[s] = mean(res_gpu.times)/10^6\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Explain, test, the following\n",
    "\n",
    "- Check at anytime how much memory is available in the GPU\n",
    "- Check at which device the GPUArray  is beeing send to, decide how to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = @benchmark A_mul_B!(X_result_gpu, X_gpu, X_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "println(\"mean time taken: \", mean(res.times)/10^6, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArrayFire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ArrayFire\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU and OpenCL\n"
     ]
    }
   ],
   "source": [
    "getAvailableBackends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayFire v3.3.2 (OpenCL, 64-bit Mac OSX, build f65dd97)\n",
      "[0] APPLE   : AMD Radeon HD - FirePro D300 Compute Engine, 2048 MB\n",
      "-1- APPLE   : AMD Radeon HD - FirePro D300 Compute Engine, 2048 MB\n"
     ]
    }
   ],
   "source": [
    "ArrayFire.AFInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0x00000000,0x00000001,0x00000004)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ArrayFire.AF_BACKEND_DEFAULT, ArrayFire.AF_BACKEND_CPU, ArrayFire.AF_BACKEND_OPENCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switch backends for computations during execution:  ```setBackend``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Backend\n"
     ]
    }
   ],
   "source": [
    "setBackend(AF_BACKEND_CPU) #Switch back to CPU backend\n",
    "getActiveBackend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayFire v3.3.2 (CPU, 64-bit Mac OSX, build f65dd97)\n",
      "[0] Unknown: Unknown, 32768 MB, Max threads(1) \n"
     ]
    }
   ],
   "source": [
    "ArrayFire.AFInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCL Backend\n"
     ]
    }
   ],
   "source": [
    "setBackend(AF_BACKEND_OPENCL) #Switch to OPENCL backend\n",
    "getActiveBackend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayFire v3.3.2 (OpenCL, 64-bit Mac OSX, build f65dd97)\n",
      "[0] APPLE   : AMD Radeon HD - FirePro D300 Compute Engine, 2048 MB\n",
      "-1- APPLE   : AMD Radeon HD - FirePro D300 Compute Engine, 2048 MB\n"
     ]
    }
   ],
   "source": [
    "ArrayFire.AFInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AFArray Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1000 Array{Float32,2}:\n",
       " 0.571312  0.697011  0.879106   …  0.400494   0.811225    0.384668  \n",
       " 0.183041  0.668708  0.0602257     0.0962854  0.240068    0.615246  \n",
       " 0.419585  0.44442   0.121419      0.566939   0.0801314   0.574808  \n",
       " 0.341526  0.387929  0.619143      0.599713   0.00970275  0.596939  \n",
       " 0.35592   0.941023  0.301473      0.052276   0.670344    0.637076  \n",
       " 0.945409  0.642618  0.161548   …  0.652432   0.842524    0.278593  \n",
       " 0.200232  0.603488  0.390178      0.984458   0.0719123   0.0824463 \n",
       " 0.780205  0.342922  0.325967      0.745449   0.776394    0.443762  \n",
       " 0.171331  0.128021  0.889548      0.878686   0.60608     0.17696   \n",
       " 0.797794  0.129769  0.1165        0.306394   0.614774    0.87428   \n",
       " 0.585677  0.567981  0.541071   …  0.594755   0.354125    0.620547  \n",
       " 0.844262  0.255532  0.0530294     0.0879742  0.531512    0.704695  \n",
       " 0.103627  0.599612  0.983694      0.0529969  0.361663    0.978394  \n",
       " ⋮                              ⋱                                   \n",
       " 0.560438  0.355688  0.751934      0.0377581  0.230848    0.501012  \n",
       " 0.086864  0.498438  0.1773        0.832501   0.831348    0.483883  \n",
       " 0.961356  0.88579   0.594302   …  0.398967   0.993692    0.487378  \n",
       " 0.774252  0.759527  0.0241104     0.680559   0.969798    0.283747  \n",
       " 0.990473  0.40429   0.925834      0.0423097  0.062235    0.810192  \n",
       " 0.168336  0.513063  0.421282      0.610893   0.0620129   0.681876  \n",
       " 0.664958  0.957307  0.473173      0.740346   0.127477    0.13694   \n",
       " 0.163282  0.819631  0.959645   …  0.194687   0.36355     0.00330879\n",
       " 0.802272  0.729652  0.711425      0.208656   0.930139    0.954374  \n",
       " 0.246308  0.609655  0.522646      0.5115     0.81249     0.413921  \n",
       " 0.495193  0.487858  0.904329      0.929642   0.527417    0.349911  \n",
       " 0.7258    0.242916  0.404544      0.311975   0.246367    0.914266  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = Array{Float32}(rand(1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1000 ArrayFire.AFArray{Float32,2}:\n",
       " 0.571312  0.697011  0.879106   …  0.400494   0.811225    0.384668  \n",
       " 0.183041  0.668708  0.0602257     0.0962854  0.240068    0.615246  \n",
       " 0.419585  0.44442   0.121419      0.566939   0.0801314   0.574808  \n",
       " 0.341526  0.387929  0.619143      0.599713   0.00970275  0.596939  \n",
       " 0.35592   0.941023  0.301473      0.052276   0.670344    0.637076  \n",
       " 0.945409  0.642618  0.161548   …  0.652432   0.842524    0.278593  \n",
       " 0.200232  0.603488  0.390178      0.984458   0.0719123   0.0824463 \n",
       " 0.780205  0.342922  0.325967      0.745449   0.776394    0.443762  \n",
       " 0.171331  0.128021  0.889548      0.878686   0.60608     0.17696   \n",
       " 0.797794  0.129769  0.1165        0.306394   0.614774    0.87428   \n",
       " 0.585677  0.567981  0.541071   …  0.594755   0.354125    0.620547  \n",
       " 0.844262  0.255532  0.0530294     0.0879742  0.531512    0.704695  \n",
       " 0.103627  0.599612  0.983694      0.0529969  0.361663    0.978394  \n",
       " ⋮                              ⋱                                   \n",
       " 0.560438  0.355688  0.751934      0.0377581  0.230848    0.501012  \n",
       " 0.086864  0.498438  0.1773        0.832501   0.831348    0.483883  \n",
       " 0.961356  0.88579   0.594302   …  0.398967   0.993692    0.487378  \n",
       " 0.774252  0.759527  0.0241104     0.680559   0.969798    0.283747  \n",
       " 0.990473  0.40429   0.925834      0.0423097  0.062235    0.810192  \n",
       " 0.168336  0.513063  0.421282      0.610893   0.0620129   0.681876  \n",
       " 0.664958  0.957307  0.473173      0.740346   0.127477    0.13694   \n",
       " 0.163282  0.819631  0.959645   …  0.194687   0.36355     0.00330879\n",
       " 0.802272  0.729652  0.711425      0.208656   0.930139    0.954374  \n",
       " 0.246308  0.609655  0.522646      0.5115     0.81249     0.413921  \n",
       " 0.495193  0.487858  0.904329      0.929642   0.527417    0.349911  \n",
       " 0.7258    0.242916  0.404544      0.311975   0.246367    0.914266  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agpu = AFArray(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.360405 seconds (9.40 k allocations: 4.190 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000×1000 Array{Float32,2}:\n",
       " 252.973  255.343  262.824  254.598  …  254.989  251.326  249.514  258.124\n",
       " 243.001  242.861  245.759  243.964     244.97   245.308  240.241  239.535\n",
       " 253.616  248.869  252.994  254.093     247.616  241.224  241.607  248.999\n",
       " 258.079  249.724  260.796  255.834     253.508  241.478  245.729  250.739\n",
       " 251.993  248.074  255.303  252.834     247.095  246.556  239.484  250.107\n",
       " 257.595  254.186  260.427  252.698  …  255.043  251.096  247.379  255.697\n",
       " 248.132  252.39   253.137  250.689     241.508  239.179  241.867  247.722\n",
       " 252.646  261.812  258.734  256.198     251.428  253.451  250.696  257.861\n",
       " 251.683  248.79   251.288  248.509     252.75   251.854  240.841  255.1  \n",
       " 248.797  237.538  250.509  246.736     242.254  240.938  244.611  241.611\n",
       " 253.103  249.476  255.488  253.429  …  250.051  245.918  244.799  253.219\n",
       " 251.404  247.981  249.552  249.5       250.045  244.938  244.55   244.835\n",
       " 258.227  251.609  253.115  255.154     252.901  240.481  245.944  256.599\n",
       "   ⋮                                 ⋱                                    \n",
       " 244.831  237.655  242.423  246.198     246.142  235.028  232.578  240.092\n",
       " 256.017  254.419  253.707  259.6       251.449  251.214  247.434  254.349\n",
       " 254.866  247.752  251.32   249.758  …  252.879  241.387  242.56   247.852\n",
       " 255.48   251.718  253.975  252.187     249.668  252.681  244.003  252.78 \n",
       " 255.197  252.459  250.01   255.471     251.508  246.628  246.291  252.332\n",
       " 253.623  249.959  253.023  249.719     249.989  250.096  247.378  254.898\n",
       " 248.848  245.456  245.783  248.312     248.611  243.802  243.562  244.488\n",
       " 256.533  248.39   250.481  253.082  …  252.31   246.818  244.961  252.61 \n",
       " 248.84   242.18   251.298  248.079     246.043  244.155  239.33   244.568\n",
       " 255.911  248.47   252.69   250.662     250.849  249.97   247.461  250.262\n",
       " 260.742  252.183  263.137  255.556     252.794  255.718  248.732  258.446\n",
       " 252.554  249.324  250.622  252.236     242.915  245.504  242.798  249.792"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time res = Array(Agpu*Agpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.455368 seconds (378.12 k allocations: 16.868 MB, 1.26% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time res =A *A;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bring computation from the GPU to the CPU: Just Array(AFArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_to_device = AFArray(rand(100,100));\n",
    "device_to_host = Array(host_to_device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Little Example with MNIST and a softmax\n",
    "\n",
    "\n",
    "- More details about softmax http://cs231n.github.io/linear-classify/#softmax\n",
    "- http://cs231n.github.io/neural-networks-case-study/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = MNIST.traindata()\n",
    "X_test, y_test = MNIST.testdata()\n",
    "n_features = size(X_train)[1]\n",
    "\n",
    "T = Float32\n",
    "X_train = Array{T}( (X_train - minimum(X_train))/(maximum(X_train) - minimum(X_train)) )\n",
    "y_train = Array{Int32}(y_train) + 1\n",
    "X_test = Array{T}(X_test - minimum(X_test))/(maximum(X_test) - minimum(X_test)) \n",
    "y_test = Array{Int32}(y_test) + 1 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_X_train = AFArray(X_train)\n",
    "g_y_train = AFArray(y_train)\n",
    "g_X_test = AFArray(X_test)\n",
    "g_y_test = AFArray(y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Softmax\n",
    "    W\n",
    "    b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Softmax(Float32[0.0622508 0.0666868 … 0.0387792 0.115878; -0.170409 -0.0260312 … -0.0186933 -0.0612406; … ; -0.11641 0.037459 … -0.0264259 -0.0925197; 0.263111 -0.0593193 … -0.167753 -0.107716],Float32[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 500\n",
    "n_classes = 10\n",
    "\n",
    "W = Array{T}(randn(n_classes, n_features)/10);\n",
    "b =  Array{T}(zeros(n_classes))\n",
    "\n",
    "g_W = AFArray(W)\n",
    "g_b = AFArray(b);\n",
    "\n",
    "s = Softmax(g_W,g_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function score(s::Softmax, minibatch )\n",
    "    return s.W * minibatch .+ s.b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "probability (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function probability(scores)\n",
    "    return exp.(scores) ./ sum( exp.(scores), 2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minibatch = g_X_train[:,1:batch_size]\n",
    "y_minibatch = g_y_train[1:batch_size];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×25 ArrayFire.AFArray{Float32,2}:\n",
       "  0.437946    1.89439   -0.545094   …   0.601925    0.16521    -0.00559358\n",
       " -0.998376   -2.25608    0.0664899      0.0650496  -0.944304   -1.8298    \n",
       " -1.17351    -1.56137    0.367401      -0.450058    0.219386    0.405007  \n",
       "  0.0604159   0.117146  -2.21337        0.169649    0.0888343   0.499621  \n",
       "  2.19321     2.9        0.549265       1.10683     0.609013    1.55207   \n",
       "  0.464647   -0.163695   0.824697   …  -0.98627    -0.70309     0.204114  \n",
       " -0.305093   -0.346913  -0.0929131     -1.05043    -0.645083   -0.587201  \n",
       "  1.42406     0.38135    0.468984       1.10203     0.725008    1.53904   \n",
       "  1.30162     1.61071    0.719225      -0.209154    0.547341    0.024211  \n",
       "  0.367061   -0.704601   0.583259       1.13642     0.0245456   0.747804  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = score(s, X_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×25 ArrayFire.AFArray{Float32,2}:\n",
       " 0.0335234  0.143838    0.0125435   …  0.0394969  0.0255211  0.021514 \n",
       " 0.0321258  0.00913354  0.0931793      0.0930452  0.0339107  0.0139886\n",
       " 0.0160636  0.0108992   0.0749983      0.0331157  0.0646799  0.0778724\n",
       " 0.0449686  0.0475935   0.00462827     0.050159   0.0462649  0.0697676\n",
       " 0.0664078  0.13464     0.0128311      0.0224085  0.0136211  0.0349766\n",
       " 0.0656902  0.0350441   0.0941604   …  0.0153949  0.0204342  0.0506236\n",
       " 0.0507877  0.0487075   0.0627924      0.0241024  0.0361495  0.0383037\n",
       " 0.0549219  0.0193598   0.021133       0.0398005  0.0272993  0.0616139\n",
       " 0.0504634  0.0687408   0.0281869      0.0111393  0.0237355  0.0140672\n",
       " 0.0221116  0.00757188  0.0274482      0.0477252  0.0156989  0.0323575"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = probability(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an array probs where each col now contains the class probabilities.\n",
    "\n",
    "In particular, since we’ve normalized them every row now sums to one. We can now query for the log probabilities assigned to the correct classes in each example:\n",
    "\n",
    "    [probs[i,j] for (i,j) in zip(minibatch_true_classes,minibatch_indicies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×4 ArrayFire.AFArray{Float32,2}:\n",
       " 0.0335234  0.143838    0.0125435   0.034166 \n",
       " 0.0321258  0.00913354  0.0931793   0.032665 \n",
       " 0.0160636  0.0108992   0.0749983   0.0546305\n",
       " 0.0449686  0.0475935   0.00462827  0.0455214\n",
       " 0.0664078  0.13464     0.0128311   0.0145251\n",
       " 0.0656902  0.0350441   0.0941604   0.016326 \n",
       " 0.0507877  0.0487075   0.0627924   0.0346881\n",
       " 0.0549219  0.0193598   0.021133    0.020089 \n",
       " 0.0504634  0.0687408   0.0281869   0.0203961\n",
       " 0.0221116  0.00757188  0.0274482   0.0147299"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int32,1}:\n",
       " 6\n",
       " 1\n",
       " 5\n",
       " 2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float32,1}:\n",
       " 0.0656902\n",
       " 0.143838 \n",
       " 0.0128311\n",
       " 0.032665 "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[probs[i,j] for (i,j) in zip(y_train[1:4],1:4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The array correct_logprobs is a Vector of just the probabilities assigned to the correct classes for each example.\n",
    "\n",
    "- The full loss is then the average of these log probabilities and the regularization loss:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3448548f0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs_correct_classes = [-log(probs[i,j]) for (i,j) in zip(y_minibatch, 1:length(y_minibatch))]\n",
    "data_loss = sum(logprobs_correct_classes)/length(logprobs_correct_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient of the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "indicies_to_modify = [ y + n_classes*(i-1) for (i,y) in enumerate(y_minibatch)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×25 Array{Int64,2}:\n",
       " 6  11  25  32  50  53  62  74  82  95  …  187  200  205  211  230  232  242"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies_to_modify'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×25 Array{Float32,2}:\n",
       " 0.0335234  0.143838    0.0125435   …  0.0394969  0.0255211  0.021514 \n",
       " 0.0321258  0.00913354  0.0931793      0.0930452  0.0339107  0.0139886\n",
       " 0.0160636  0.0108992   0.0749983      0.0331157  0.0646799  0.0778724\n",
       " 0.0449686  0.0475935   0.00462827     0.050159   0.0462649  0.0697676\n",
       " 0.0664078  0.13464     0.0128311      0.0224085  0.0136211  0.0349766\n",
       " 0.0656902  0.0350441   0.0941604   …  0.0153949  0.0204342  0.0506236\n",
       " 0.0507877  0.0487075   0.0627924      0.0241024  0.0361495  0.0383037\n",
       " 0.0549219  0.0193598   0.021133       0.0398005  0.0272993  0.0616139\n",
       " 0.0504634  0.0687408   0.0281869      0.0111393  0.0237355  0.0140672\n",
       " 0.0221116  0.00757188  0.0274482      0.0477252  0.0156989  0.0323575"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dscores = zeros(probs)\n",
    "dscores .= probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021514006f0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dscores[24*10+1] # first position last example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03235753f0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dscores[10*25] # last position from last example in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to every position to be modified (the ones with the correct class) and substract 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dscores[indicies_to_modify] -= 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×25 Array{Float32,2}:\n",
       "  0.00134094   -0.0342465     0.00050174   …   0.00102085    0.00086056 \n",
       "  0.00128503    0.000365342   0.00372717      -0.0386436    -0.0394405  \n",
       "  0.000642544   0.000435969   0.00299993       0.0025872     0.0031149  \n",
       "  0.00179875    0.00190374    0.000185131      0.0018506     0.00279071 \n",
       "  0.00265631    0.00538559   -0.0394868        0.000544843   0.00139906 \n",
       " -0.0373724     0.00140176    0.00376641   …   0.00081737    0.00202494 \n",
       "  0.00203151    0.0019483     0.00251169       0.00144598    0.00153215 \n",
       "  0.00219688    0.000774394   0.00084532       0.00109197    0.00246456 \n",
       "  0.00201854    0.00274963    0.00112747       0.000949421   0.000562686\n",
       "  0.000884465   0.000302875   0.00109793       0.000627954   0.0012943  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dscores ./= length(y_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,25),(25,10),(784,10),(10,784))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(X_minibatch), size(dscores'), size(X_minibatch*dscores'), size(s.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,25),(25,784))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(dscores),size(X_minibatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " -0.04      \n",
       " -0.2       \n",
       " -0.04      \n",
       " -0.08      \n",
       " -0.08      \n",
       " -0.04      \n",
       " -0.04      \n",
       "  2.56114f-9\n",
       "  2.96859f-9\n",
       " -0.08      "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nabla_W = A_mul_Bt(dscores, X_minibatch);\n",
    "nabla_b = vec(sum(dscores,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,784)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(nabla_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient_softmax (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gradient_softmax(s::Softmax, X_minibatch, y_minibatch::AbstractVector)\n",
    "    n_classes = length(s.b)\n",
    "    n_samples = length(y_minibatch)\n",
    "    \n",
    "    scores = score(s, X_minibatch)\n",
    "    probs = probability(sc)\n",
    "\n",
    "    indicies_to_modify = [y + n_classes*(i-1) for (i,y) in enumerate(y_minibatch)]\n",
    "    dscores = probs\n",
    "    dscores[indicies_to_modify] -= 1;\n",
    "    dscores ./= length(y_minibatch)\n",
    "\n",
    "    nabla_W = A_mul_Bt(dscores, X_minibatch)\n",
    "    nabla_b = vec(sum(dscores,2))    \n",
    "    return nabla_W, nabla_b, data_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.794697 seconds (341.44 k allocations: 14.944 MB, 0.62% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time  gradient_softmax(s, X_minibatch, y_minibatch);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient_softmax2 (generic function with 1 method)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gradient_softmax2(s::Softmax, X_minibatch::AbstractMatrix, Y_minibatch::AbstractMatrix)\n",
    "    n_classes = length(s.b)\n",
    "    n_samples = length(y_minibatch)\n",
    "    \n",
    "    probs = probability(score(s, X_minibatch))\n",
    "    dscores = probs - Y_minibatch\n",
    "\n",
    "    data_loss = -sum( Y_minibatch.*log(probs))/n_samples\n",
    "    nabla_W = A_mul_Bt(dscores, X_minibatch)/n_samples\n",
    "    nabla_b = vec(sum(dscores,2))/n_samples\n",
    "    \n",
    "    return nabla_W, nabla_b, data_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one_hot_encoding (generic function with 1 method)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function one_hot_encoding(y_train)\n",
    "    unique_classes = sort(unique(y_train))\n",
    "    class_to_pos = Dict(class =>pos for (pos,class) in enumerate(unique_classes))    \n",
    "    encoded_classes = zeros(length(unique_classes), length(y_train))\n",
    "    for (i,y) in enumerate(y_train)\n",
    "        encoded_classes[class_to_pos[y],i] = 1\n",
    "    end\n",
    "    return encoded_classes\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Array{Float32}(one_hot_encoding(y_train))\n",
    "Y_train = AFArray(Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching gradient_softmax(::Softmax, ::ArrayFire.AFArray{Float32,2}, ::ArrayFire.AFArray{Float32,2})\u001b[0m\nClosest candidates are:\n  gradient_softmax(::Softmax, ::Any, \u001b[1m\u001b[31m::AbstractArray{T,1}\u001b[0m) at In[42]:2\u001b[0m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching gradient_softmax(::Softmax, ::ArrayFire.AFArray{Float32,2}, ::ArrayFire.AFArray{Float32,2})\u001b[0m\nClosest candidates are:\n  gradient_softmax(::Softmax, ::Any, \u001b[1m\u001b[31m::AbstractArray{T,1}\u001b[0m) at In[42]:2\u001b[0m",
      ""
     ]
    }
   ],
   "source": [
    "@time  gradient_softmax(s, X_minibatch, Y_train[:,1:25]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Softmax(Float32[0.0327769 -0.125568 … 0.204383 0.00964492; -0.0547601 -0.129532 … -0.0646045 -0.112268; … ; -0.121336 -0.253113 … 0.154665 0.352933; 0.114556 -0.200836 … -0.0107951 -0.0830136],Float32[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 500\n",
    "n_classes = 10\n",
    "\n",
    "W = Array{T}(randn(n_classes, n_features)/10);\n",
    "b =  Array{T}(zeros(n_classes))\n",
    "\n",
    "g_W = AFArray(W)\n",
    "g_b = AFArray(b);\n",
    "\n",
    "s = Softmax(g_W,g_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minibatch = X_train[:,1:100]\n",
    "Y_minibatch = Y_train[:,1:100];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.954621 seconds (6.57 M allocations: 126.905 MB, 0.80% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0],\n",
       "\n",
       "Float32[-0.48,-0.52,-0.2,-0.4,-0.4,-0.16,-0.4,-0.36,-0.28,-0.4],18.89552f0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time gradient_softmax2(s, X_minibatch, Y_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "norm(s.W): 8.891143"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching gradient_softmax(::Softmax, ::Array{Float32,2}, ::ArrayFire.AFArray{Float32,2})\u001b[0m\nClosest candidates are:\n  gradient_softmax(::Softmax, ::Any, \u001b[1m\u001b[31m::AbstractArray{T,1}\u001b[0m) at In[42]:2\u001b[0m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching gradient_softmax(::Softmax, ::Array{Float32,2}, ::ArrayFire.AFArray{Float32,2})\u001b[0m\nClosest candidates are:\n  gradient_softmax(::Softmax, ::Any, \u001b[1m\u001b[31m::AbstractArray{T,1}\u001b[0m) at In[42]:2\u001b[0m",
      ""
     ]
    }
   ],
   "source": [
    "print(\"\\nnorm(s.W): \", norm(s.W))\n",
    "nabla_W, nabla_b, data_loss = gradient_softmax(s, X_minibatch, Y_minibatch)\n",
    "s.W .-= lr .* nabla_W\n",
    "s.b .-= lr .* nabla_b\n",
    "print(\"\\nloss: \", data_loss)\n",
    "print(\"\\nnorm(s.W): \", norm(s.W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "norm(s.W): 8.891143"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching gradient_softmax(::Softmax, ::Array{Float32,2}, ::ArrayFire.AFArray{Float32,2})\u001b[0m\nClosest candidates are:\n  gradient_softmax(::Softmax, ::Any, \u001b[1m\u001b[31m::AbstractArray{T,1}\u001b[0m) at In[42]:2\u001b[0m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching gradient_softmax(::Softmax, ::Array{Float32,2}, ::ArrayFire.AFArray{Float32,2})\u001b[0m\nClosest candidates are:\n  gradient_softmax(::Softmax, ::Any, \u001b[1m\u001b[31m::AbstractArray{T,1}\u001b[0m) at In[42]:2\u001b[0m",
      ""
     ]
    }
   ],
   "source": [
    "print(\"\\nnorm(s.W): \", norm(s.W))\n",
    "nabla_W, nabla_b, data_loss = gradient_softmax(s, X_minibatch, Y_minibatch)\n",
    "s.W .-= lr .* nabla_W\n",
    "s.b .-= lr .* nabla_b\n",
    "print(\"\\nloss: \", data_loss)\n",
    "print(\"\\nnorm(s.W): \", norm(s.W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "n_classes = 10\n",
    "\n",
    "W = Array{T}(randn(n_classes, n_features)/10);\n",
    "b =  Array{T}(zeros(n_classes))\n",
    "g_W = AFArray(W)\n",
    "g_b = AFArray(b);\n",
    "s = Softmax(g_W,g_b)\n",
    "\n",
    "lr = Float32(0.05)\n",
    "print_every = 10\n",
    "n_samples = size(X_minibatch)[2]\n",
    "\n",
    "for i in 1:15\n",
    "    nabla_W, nabla_b, data_loss = gradient_softmax(s, X_minibatch, Y_minibatch)\n",
    "    s.W .-= lr .* nabla_W\n",
    "    s.b .-= lr .* nabla_b\n",
    "    print(\"\\niter: \", i , \"  loss: \", data_loss)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?? What's up with the cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000827 seconds (154 allocations: 130.156 KB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0],\n",
       "\n",
       "Float32[-0.8,-1.0,-0.76,-0.8,-0.8,-0.48,-0.72,-0.8,-0.56,-0.88],39.98738f0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time gradient_softmax(s, X_minibatch, Y_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching gradient_softmax(::Softmax, ::Array{Float32,2}, ::Array{Float32,2})\u001b[0m\nClosest candidates are:\n  gradient_softmax(::Softmax, ::Any, \u001b[1m\u001b[31m::AbstractArray{T,1}\u001b[0m) at In[42]:2\u001b[0m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching gradient_softmax(::Softmax, ::Array{Float32,2}, ::Array{Float32,2})\u001b[0m\nClosest candidates are:\n  gradient_softmax(::Softmax, ::Any, \u001b[1m\u001b[31m::AbstractArray{T,1}\u001b[0m) at In[42]:2\u001b[0m",
      "",
      " in macro expansion; at ./In[53]:16 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "n_classes = 10\n",
    "\n",
    "W = Array{T}(randn(n_classes, n_features)/10);\n",
    "b =  Array{T}(zeros(n_classes))\n",
    "s = Softmax(W,b)\n",
    "\n",
    "X_minibatch = X_train[:,1:batch_size]\n",
    "Y_minibatch = Array{Float32}(one_hot_encoding(y_train))[:,1:batch_size];\n",
    "\n",
    "lr = Float32(0.01)\n",
    "print_every = 10 \n",
    "n_samples = size(X_minibatch)[2]\n",
    "\n",
    "for i in 1:15\n",
    "    nabla_W, nabla_b, data_loss = gradient_softmax(s, X_minibatch, Y_minibatch)\n",
    "    s.W .-= lr .* nabla_W\n",
    "    s.b .-= lr .* nabla_b\n",
    "    print(\"\\niter: \", i , \"  loss: \", data_loss)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # number of points per class\n",
    "D = 2 # dimensionality\n",
    "K = 3 # number of classes\n",
    "X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
    "y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "\n",
    "num_examples = X.shape[0]\n",
    "\n",
    "\n",
    "for j in range(K):\n",
    "  ix = range(N*j,N*(j+1))\n",
    "  r = np.linspace(0.0,1,N) # radius\n",
    "  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
    "  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "  y[ix] = j\n",
    "end\n",
    "# lets visualize the data:\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

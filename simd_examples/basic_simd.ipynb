{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Simd examples\n",
    "\n",
    "\n",
    "First of all, to ensure that you can use simd instructions, run \n",
    "```\n",
    "include(joinpath(dirname(JULIA_HOME),\"share\",\"julia\",\"build_sysimg.jl\")); build_sysimg(force=true)\n",
    "```\n",
    "if julia is not build in source.\n",
    "\n",
    "- https://discourse.julialang.org/t/does-julia-use-simd-instructions-for-broadcast-operations/2492/18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making operations in a big array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/davidbuchacaprats/.julia/compiled/v1.1/BenchmarkTools/ZXPQo.ji for BenchmarkTools [6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf]\n",
      "└ @ Base loading.jl:1184\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_simd (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum(a::Vector)\n",
    "    total = zero(eltype(a))\n",
    "    for x in a\n",
    "        total += x\n",
    "    end\n",
    "    return total\n",
    "end\n",
    "\n",
    "function mysum_simd(a::Vector)\n",
    "    total = zero(eltype(a))\n",
    "    @simd for x in a\n",
    "        total += x\n",
    "    end\n",
    "    return total\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @simd macro\n",
    "\n",
    "When we use the `@simd` macro the for loop gets changed by a set a couple of loops. The main idea is that operations that are done \"sequentially\" can be done at the sime time for a given simd width.\n",
    "\n",
    "\n",
    "Instead of doing: `total = 0; total += x[1]; ... ;total += x[n] `. We can do the same operation (in this case `+`) on `n_simd` elements at the same time (for the same cost we can do a single `+` operation). If we had 10 elements and  `n_simd=4` we could make 3 sums (instead of 10) followed by a sum of the 3 partial results. The partial results would contain the partial sums, one from `x[1:4]`, another from `x[4:8]` and the last one from `x[8:10]`.\n",
    "\n",
    "In this case it is likely that the overhead produced by the `@simd` is not worth the effort. Nevertheless, these instructions become paramount when operations on arrays of thousands of elements.\n",
    "\n",
    "We can see the internals of `@simd` macro in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quote\n",
       "    #= simdloop.jl:65 =#\n",
       "    let ##r#367 = a\n",
       "        #= simdloop.jl:66 =#\n",
       "        for ##i#368 = Base.simd_outer_range(##r#367)\n",
       "            #= simdloop.jl:67 =#\n",
       "            let ##n#369 = Base.simd_inner_length(##r#367, ##i#368)\n",
       "                #= simdloop.jl:68 =#\n",
       "                if zero(##n#369) < ##n#369\n",
       "                    #= simdloop.jl:70 =#\n",
       "                    let ##i#370 = zero(##n#369)\n",
       "                        #= simdloop.jl:71 =#\n",
       "                        while ##i#370 < ##n#369\n",
       "                            #= simdloop.jl:72 =#\n",
       "                            local x = Base.simd_index(##r#367, ##i#368, ##i#370)\n",
       "                            #= simdloop.jl:73 =#\n",
       "                            begin\n",
       "                                #= In[3]:2 =#\n",
       "                                total += x\n",
       "                            end\n",
       "                            #= simdloop.jl:74 =#\n",
       "                            ##i#370 += 1\n",
       "                            #= simdloop.jl:75 =#\n",
       "                            $(Expr(:simdloop, false))\n",
       "                        end\n",
       "                    end\n",
       "                end\n",
       "            end\n",
       "        end\n",
       "    end\n",
       "    #= simdloop.jl:82 =#\n",
       "    nothing\n",
       "end"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@macroexpand @simd for x in a\n",
    "        total += x\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Float type impact\n",
    "\n",
    "The following benchmarks show that\n",
    "\n",
    "- `mysum_simd` is is twice faster with `Float32` than with `Float64`.\n",
    "- `mysum_simd` and `mysum` are much slower with `Float16`than with `Float32` and `Float64` (probably because there are not `Float16` instructions called in this processor).\n",
    "\n",
    "\n",
    "The test found in the next cell can give  you different results if you installed julia from source or not. You can use the provided script with the command `julia execute_this.jl` to build it from source.\n",
    "\n",
    "```julia\n",
    "\n",
    "# with execute_this.jl executed\n",
    "mysum_simd      float64:    Trial(10.411 μs)\n",
    "mysum           float64:    Trial(89.152 μs)\n",
    "\n",
    "mysum_simd      float32:    Trial(5.035 μs)\n",
    "mysum           float32:    Trial(89.168 μs)\n",
    "\n",
    "mysum_simd      float16:    Trial(846.852 μs)\n",
    "mysum           float16:    Trial(820.405 μs)\n",
    "\n",
    "\n",
    "# with execute_this.jl executed\n",
    "mysum_simd      float64:    Trial(22.340 μs)\n",
    "mysum           float64:    Trial(89.161 μs)\n",
    "\n",
    "mysum_simd      float32:    Trial(11.210 μs)\n",
    "mysum           float32:    Trial(89.170 μs)\n",
    "\n",
    "mysum_simd      float16:    Trial(817.455 μs)\n",
    "mysum           float16:    Trial(817.467 μs)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysum_simd      float64:    Trial(23.326 μs)\n",
      "mysum           float64:    Trial(83.620 μs)\n",
      "\n",
      "mysum_simd      float32:    Trial(11.154 μs)\n",
      "mysum           float32:    Trial(83.614 μs)\n",
      "\n",
      "mysum_simd      float16:    Trial(811.922 μs)\n",
      "mysum           float16:    Trial(845.870 μs)\n"
     ]
    }
   ],
   "source": [
    "# with execute_this.jl executed\n",
    "x = rand(Float64 , 100000);\n",
    "println(\"mysum_simd      float64:    \", @benchmark mysum_simd(x))\n",
    "println(\"mysum           float64:    \", @benchmark mysum(x))\n",
    "\n",
    "x = rand(Float32 , 100000);\n",
    "println()\n",
    "println(\"mysum_simd      float32:    \", @benchmark mysum_simd(x))\n",
    "println(\"mysum           float32:    \", @benchmark mysum(x))\n",
    "\n",
    "println()\n",
    "x = rand(Float16 , 100000);\n",
    "println(\"mysum_simd      float16:    \", @benchmark mysum_simd(x))\n",
    "println(\"mysum           float16:    \", @benchmark mysum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@code_native mysum_simd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@code_native mysum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example cost function simd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function MSE_simd{T}(y::Vector{T},y_pred::Vector{T})\n",
    "   cost = zero(eltype(y))\n",
    "   @simd for i in 1:length(y)\n",
    "       @inbounds cost += (y[i] - y_pred[i])^2\n",
    "   end\n",
    "   return sqrt(cost)\n",
    "end\n",
    "\n",
    "function MSE{T}(y::Vector{T},y_pred::Vector{T})\n",
    "   cost = zero(eltype(y))\n",
    "    \n",
    "    @inbounds for i in 1:length(y)\n",
    "        cost += (y[i] - y_pred[i])^2\n",
    "    end\n",
    "    return sqrt(cost)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE             float64:    Trial(89.164 μs)\n",
      "MSE_simd        float64:    Trial(19.770 μs)\n",
      "\n",
      "MSE             float32:    Trial(89.176 μs)\n",
      "MSE_simd        float32:    Trial(9.935 μs)\n",
      "\n",
      "MSE             float16:    Trial(2.720 ms)\n",
      "MSE_simd        float16:    Trial(2.719 ms)\n"
     ]
    }
   ],
   "source": [
    "y     =  rand(Float64 , 100000);\n",
    "y_hat =  rand(Float64 , 100000);\n",
    "println(\"MSE             float64:    \", @benchmark MSE(y,y_hat))\n",
    "println(\"MSE_simd        float64:    \", @benchmark MSE_simd(y,y_hat))\n",
    "\n",
    "y     =  rand(Float32 , 100000);\n",
    "y_hat =  rand(Float32 , 100000);\n",
    "println()\n",
    "println(\"MSE             float32:    \", @benchmark MSE(y,y_hat))\n",
    "println(\"MSE_simd        float32:    \", @benchmark MSE_simd(y,y_hat))\n",
    "\n",
    "y     =  rand(Float16 , 100000);\n",
    "y_hat =  rand(Float16 , 100000);\n",
    "println()\n",
    "println(\"MSE             float16:    \", @benchmark MSE(y,y_hat))\n",
    "println(\"MSE_simd        float16:    \", @benchmark MSE_simd(y,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross entropy minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = Float32\n",
    "p_y_given_x = rand(T, 10, 256);\n",
    "onehot_y = zeros(T, 10, 256);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×256 Array{Float32,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Another exmaple\n",
    "\n",
    "- https://discourse.julialang.org/t/speeding-up-fvm-code/8430/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     16.898 ms (0.00% GC)\n",
       "  median time:      17.038 ms (0.00% GC)\n",
       "  mean time:        17.124 ms (0.00% GC)\n",
       "  maximum time:     19.012 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          292\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rhs!(divergence,Nv,Nw,invDv,invDw,g,V,W)\n",
    "    # this is type stable!!\n",
    "    @inbounds for i=1:Nv\n",
    "        for j= Nw:-1:1\n",
    "            # Values\n",
    "            gij  = g[j,i]\n",
    "            gimj = i > 1         ? g[j,i-1]:zero(gij)\n",
    "            gipj = (i+1) <= Nv   ? g[j,i+1]:zero(gij)\n",
    "\n",
    "            gijp = j+1 < Nw      ? g[j+1,i]:zero(gij)\n",
    "            gijm = j-1 >= 1      ? g[j-1,i]:zero(gij)\n",
    "            # Upwind fluxes + null flux boundary conditions\n",
    "            Fij  = i > 1         ? (V[j,i]>=0.  ? V[j,i]*gimj: V[j,i]  *gij): zero(gij)\n",
    "            Fipj = i < Nv        ? (V[j,i+1]>=0.? V[j,i+1]*gij:V[j,i+1]*gipj):zero(gij)\n",
    "\n",
    "            Gijp = j < Nw        ? (W[j+1,i]>0. ? W[j+1,i]*gij:W[j+1,i]*gijp):zero(gij)\n",
    "            Gij  = j>1           ? (W[j,i]>0.   ? W[j,i]*gijm: W[j,i]  *gij): zero(gij)\n",
    "            # Divergence\n",
    "            divergence[j,i] = invDv*(Fipj - Fij) + invDw*(Gijp - Gij)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "N = 2000\n",
    "divergence = rand(N,N)\n",
    "g = rand(N,N)\n",
    "V = rand(N,N)\n",
    "W = rand(N,N)\n",
    "@benchmark rhs!(divergence,N,N,1.,1.,g,V,W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     19.779 ms (0.00% GC)\n",
       "  median time:      20.044 ms (0.00% GC)\n",
       "  mean time:        20.238 ms (0.00% GC)\n",
       "  maximum time:     21.451 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          78\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function inner(i, divergence,Nv,Nw,invDv,invDw,g,V,W)\n",
    "    @inbounds for j= Nw:-1:1\n",
    "        # Values\n",
    "        gij  = g[j,i]\n",
    "        gimj = i > 1         ? g[j,i-1]:zero(gij)\n",
    "        gipj = (i+1) <= Nv   ? g[j,i+1]:zero(gij)\n",
    "\n",
    "        gijp = j+1 < Nw      ? g[j+1,i]:zero(gij)\n",
    "        gijm = j-1 >= 1      ? g[j-1,i]:zero(gij)\n",
    "        # Upwind fluxes + null flux boundary conditions\n",
    "        Fij  = i > 1         ? (V[j,i]>=0.  ? V[j,i]*gimj: V[j,i]  *gij): zero(gij)\n",
    "        Fipj = i < Nv        ? (V[j,i+1]>=0.? V[j,i+1]*gij:V[j,i+1]*gipj):zero(gij)\n",
    "\n",
    "        Gijp = j < Nw        ? (W[j+1,i]>0. ? W[j+1,i]*gij:W[j+1,i]*gijp):zero(gij)\n",
    "        Gij  = j>1           ? (W[j,i]>0.   ? W[j,i]*gijm: W[j,i]  *gij): zero(gij)\n",
    "        # Divergence\n",
    "        divergence[j,i] = invDv*(Fipj - Fij) + invDw*(Gijp - Gij)\n",
    "    end\n",
    "end\n",
    "function rhs!(divergence,Nv,Nw,invDv,invDw,g,V,W)\n",
    "    # this is type stable!!\n",
    "    Threads.@threads for i=1:Nv\n",
    "        inner(i, divergence,Nv,Nw,invDv,invDw,g,V,W)\n",
    "    end\n",
    "end\n",
    "\n",
    "using BenchmarkTools\n",
    "function init()\n",
    "    srand(42)\n",
    "    N = 2000\n",
    "    divergence = rand(N,N)\n",
    "    g = rand(N,N)\n",
    "    V = rand(N,N)\n",
    "    W = rand(N,N)\n",
    "    divergence, g, V, W\n",
    "end\n",
    "N = 2000\n",
    "@benchmark rhs!(divergence,N,N,1.,1.,g,V,W) setup= ((divergence, g, V, W) = init())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     8.527 ms (0.00% GC)\n",
       "  median time:      8.804 ms (0.00% GC)\n",
       "  mean time:        8.953 ms (0.00% GC)\n",
       "  maximum time:     10.175 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          94\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function inner(i, divergence,Nv,Nw,invDv,invDw,g,V,W)\n",
    "    @simd for j = Nw-1:-1:2\n",
    "        @inbounds begin\n",
    "            # Values\n",
    "            gij  = g[j, i]\n",
    "            gimj = g[j, i-1]\n",
    "            gipj = g[j, i+1]\n",
    "\n",
    "            gijp = g[j+1, i]\n",
    "            gijm = g[j-1, i]\n",
    "\n",
    "            # Upwind fluxes + null flux boundary conditions\n",
    "            vji = V[j,i]\n",
    "            mul1 = ifelse(vji >= 0.0, gimj, gij)\n",
    "            Fij  = vji * mul1\n",
    "            \n",
    "            vji = V[j,i+1]\n",
    "            mul1 = ifelse(vji >= 0.0, gij, gipj)\n",
    "            Fipj  = vji * mul1\n",
    "            \n",
    "            wji = W[j+1,i]\n",
    "            mul = ifelse(wji > 0.0, gij, gijp)\n",
    "            Gijp  = wji * mul\n",
    "            \n",
    "            wji = W[j,i]\n",
    "            mul = ifelse(wji > 0.0, gijm, gij)\n",
    "            Gij  = wji * mul\n",
    "\n",
    "            # Divergence\n",
    "            divergence[j,i] = invDv*(Fipj - Fij) + invDw*(Gijp - Gij)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "function rhs!(divergence,Nv,Nw,invDv,invDw,g,V,W)\n",
    "    Threads.@threads for i=2:Nv-1\n",
    "        inner(i, divergence,Nv,Nw,invDv,invDw,g,V,W)\n",
    "    end\n",
    "end\n",
    "using BenchmarkTools\n",
    "function init()\n",
    "    srand(42)\n",
    "    N = 2000\n",
    "    divergence = rand(N,N)\n",
    "    g = rand(N,N)\n",
    "    V = rand(N,N)\n",
    "    W = rand(N,N)\n",
    "    divergence, g, V, W\n",
    "end\n",
    "N = 2000\n",
    "#@btime rhs!(divergence,N,N,1.,1.,g,V,W) setup= ((divergence, g, V, W) = init())\n",
    "@benchmark rhs!(divergence,N,N,1.,1.,g,V,W) setup= ((divergence, g, V, W) = init())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### median pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0f0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://discourse.julialang.org/t/make-this-code-fast-median-pooling/6405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medmedpool55! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@inline function median5_swap(a,b,c,d,e)\n",
    "    # https://github.com/JeffreySarnoff/SortingNetworks.jl/blob/master/src/swapsort.jl\n",
    "    a,b = minmax(a,b)\n",
    "    c,d = minmax(c,d)\n",
    "    a,c = minmax(a,c)\n",
    "    b,d = minmax(b,d)\n",
    "    c,e = minmax(e,c)\n",
    "    max(c, min(e,b))\n",
    "end\n",
    "\n",
    "@inline median5(args...) = median5_swap(args...)\n",
    "\n",
    "function medmedpool55!(out::AbstractMatrix, img::AbstractMatrix)\n",
    "    @assert size(out, 1) >= size(img, 1) ÷ 5\n",
    "    @assert size(out, 2) >= size(img, 2) ÷ 5\n",
    "    @inbounds for j ∈ indices(out)[2]\n",
    "        @simd for i ∈ indices(out)[1]\n",
    "            x11 = img[5i-4, 5j-4]\n",
    "            x21 = img[5i-3, 5j-4]\n",
    "            x31 = img[5i-2, 5j-4]\n",
    "            x41 = img[5i-1, 5j-4]\n",
    "            x51 = img[5i-0, 5j-4]\n",
    "            \n",
    "            x12 = img[5i-4, 5j-3]\n",
    "            x22 = img[5i-3, 5j-3]\n",
    "            x32 = img[5i-2, 5j-3]\n",
    "            x42 = img[5i-1, 5j-3]\n",
    "            x52 = img[5i-0, 5j-3]\n",
    "            \n",
    "            x13 = img[5i-4, 5j-2]\n",
    "            x23 = img[5i-3, 5j-2]\n",
    "            x33 = img[5i-2, 5j-2]\n",
    "            x43 = img[5i-1, 5j-2]\n",
    "            x53 = img[5i-0, 5j-2]\n",
    "            \n",
    "            x14 = img[5i-4, 5j-1]\n",
    "            x24 = img[5i-3, 5j-1]\n",
    "            x34 = img[5i-2, 5j-1]\n",
    "            x44 = img[5i-1, 5j-1]\n",
    "            x54 = img[5i-0, 5j-1]\n",
    "            \n",
    "            x15 = img[5i-4, 5j-0]\n",
    "            x25 = img[5i-3, 5j-0]\n",
    "            x35 = img[5i-2, 5j-0]\n",
    "            x45 = img[5i-1, 5j-0]\n",
    "            x55 = img[5i-0, 5j-0]\n",
    "            \n",
    "            y1 = median5(x11,x12,x13,x14,x15)\n",
    "            y2 = median5(x21,x22,x23,x24,x25)\n",
    "            y3 = median5(x31,x32,x33,x34,x35)\n",
    "            y4 = median5(x41,x42,x43,x44,x45)\n",
    "            y5 = median5(x51,x52,x53,x54,x55)\n",
    "            \n",
    "            z = median5(y1,y2,y3,y4,y5)\n",
    "            out[i,j] = z\n",
    "        end\n",
    "    end\n",
    "    out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     8.746 ms (0.00% GC)\n",
       "  median time:      10.786 ms (0.00% GC)\n",
       "  mean time:        11.430 ms (0.00% GC)\n",
       "  maximum time:     47.553 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          437\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "imgs = randn(Float32, 1024,1024, 10)\n",
    "img = view(imgs, :,:,1)\n",
    "out = similar(img, size(img) .÷ 5)\n",
    "@benchmark medmedpool55!(out, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 1024, 10), (6,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(imgs),size([rand(T,N) for _ in 1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Base.@pure simdwidth(::Type{T}) where {T} = Int(256/8/sizeof(T))\n",
    "\n",
    "@inline function median3(a,b,c)\n",
    "    max(min(a,b), min(c,max(a,b)))\n",
    "end\n",
    "\n",
    "@inline function median5(a,b,c,d,e)\n",
    "    # https://stackoverflow.com/questions/480960/code-to-calculate-median-of-five-in-c-sharp\n",
    "    f=max(min(a,b),min(c,d))\n",
    "    g=min(max(a,b),max(c,d))\n",
    "    median3(e,f,g)\n",
    "end\n",
    "\n",
    "@noinline function median5_vectors!(out, a,b,c,d,e)\n",
    "    K = simdwidth(eltype(out))\n",
    "    N = length(out)\n",
    "    T = eltype(out)\n",
    "    V = Vec{K,T}\n",
    "    @assert mod(N,K) == 0\n",
    "\n",
    "    @inbounds for i in 1:K:N\n",
    "        va = vload(V,a, i)\n",
    "        vb = vload(V,b, i)\n",
    "        vc = vload(V,c, i)\n",
    "        vd = vload(V,d, i)\n",
    "        ve = vload(V,e, i)\n",
    "        vo = median5(va,vb,vc,vd,ve)\n",
    "        vstore(vo,out, i)\n",
    "    end\n",
    "    out\n",
    "end\n",
    "\n",
    "using BenchmarkTools\n",
    "T = UInt8\n",
    "T = Float32\n",
    "N = 10^6\n",
    "N = N ÷ simdwidth(T) * simdwidth(T)\n",
    "out, a,b,c,d,e = [rand(T,N) for _ in 1:6]\n",
    "@benchmark median5_vectors!(out, a,b,c,d,e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simdwidth(Float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simdwidth (generic function with 1 method)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simdwidth(::Type{T}) where {T} = Int(256/8/sizeof(T))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "simdwidth(Float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct VecElement{T}\n",
    "    value::T\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.section\t__TEXT,__text,regular,pure_instructions\n",
      "Filename: In[6]\n",
      "\tpushq\t%rbp\n",
      "\tmovq\t%rsp, %rbp\n",
      "Source line: 10\n",
      "\tmovss\t(%rsi), %xmm0           ## xmm0 = mem[0],zero,zero,zero\n",
      "\tmovss\t4(%rsi), %xmm1          ## xmm1 = mem[0],zero,zero,zero\n",
      "\tmovaps\t%xmm0, %xmm2\n",
      "\taddss\t%xmm2, %xmm2\n",
      "\tmovaps\t%xmm1, %xmm3\n",
      "\taddss\t%xmm3, %xmm3\n",
      "\tmovss\t8(%rsi), %xmm4          ## xmm4 = mem[0],zero,zero,zero\n",
      "\tmovaps\t%xmm4, %xmm5\n",
      "\taddss\t%xmm5, %xmm5\n",
      "\tmovss\t12(%rsi), %xmm6         ## xmm6 = mem[0],zero,zero,zero\n",
      "\tmovaps\t%xmm6, %xmm7\n",
      "\taddss\t%xmm7, %xmm7\n",
      "\taddss\t%xmm0, %xmm2\n",
      "\taddss\t%xmm1, %xmm3\n",
      "\taddss\t%xmm4, %xmm5\n",
      "\taddss\t%xmm6, %xmm7\n",
      "\tmovss\t%xmm2, (%rdi)\n",
      "\tmovss\t%xmm3, 4(%rdi)\n",
      "\tmovss\t%xmm5, 8(%rdi)\n",
      "\tmovss\t%xmm7, 12(%rdi)\n",
      "\tmovq\t%rdi, %rax\n",
      "\tpopq\t%rbp\n",
      "\tretq\n",
      "\tnopl\t(%rax,%rax)\n"
     ]
    }
   ],
   "source": [
    "const m128 = NTuple{4,VecElement{Float32}}\n",
    "\n",
    "function add(a::m128, b::m128)\n",
    "    (VecElement(a[1].value+b[1].value),\n",
    "     VecElement(a[2].value+b[2].value),\n",
    "     VecElement(a[3].value+b[3].value),\n",
    "     VecElement(a[4].value+b[4].value))\n",
    "end\n",
    "\n",
    "triple(c::m128) = add(add(c,c),c)\n",
    "\n",
    "code_native(triple,(m128,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
